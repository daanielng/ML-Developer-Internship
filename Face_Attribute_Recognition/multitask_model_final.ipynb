{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from imutils import paths\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input, Convolution2D, Conv2D, MaxPooling2D, Dense, Dropout, Flatten, BatchNormalization, Lambda\n",
    "\n",
    "# from tensorflow.keras.applications import ResNet101, ResNet152, ResNet50, Xception, ResNet50V2, DenseNet201, DenseNet169, InceptionV3\n",
    "from tensorflow.keras.applications import DenseNet201, ResNet50, ResNet101, Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Data Preparation #\n",
    "####################\n",
    "\n",
    "class DataGenerator():\n",
    "    def __init__(self, attribute_info):\n",
    "        self.attribute_info = attribute_info\n",
    "        self.data_path = attribute_info['data dir']\n",
    "        self.img_size = attribute_info['image size']\n",
    "        \n",
    "    # shuffle image paths and return shuffled image paths\n",
    "    def shuffle(self):\n",
    "        imagePaths = sorted(list(paths.list_images(self.data_path)))\n",
    "        random.shuffle(imagePaths)\n",
    "\n",
    "        return imagePaths\n",
    "    \n",
    "    # converts RGBA PNG to RGB\n",
    "    def format_rgb(self, image):\n",
    "        background = Image.new('RGB', image.size, (255, 255, 255))\n",
    "        background.paste(image, mask = image.split()[3])\n",
    "        return background\n",
    "\n",
    "    # save labels using pickle library\n",
    "    def save_data(self, data_lst):\n",
    "        #exclude data array\n",
    "        new_data_lst = data_lst[1:]\n",
    "\n",
    "        #create save folder\n",
    "        save_folder = os.getcwd() + '\\\\pickled_data'\n",
    "        os.mkdir(save_folder)\n",
    "\n",
    "        #get attribute name list\n",
    "        attribute_names = list(self.attribute_info['attributes'].keys())\n",
    "\n",
    "        #save data\n",
    "        for attribute_indx in range(len(attribute_names)):\n",
    "            attribute_name = attribute_names[attribute_indx]\n",
    "\n",
    "            save_path = f'{save_folder}\\\\{attribute_name}.pickle'\n",
    "\n",
    "            f = open(r'{}'.format(save_path), \"wb\")\n",
    "            f.write(pickle.dumps(new_data_lst[attribute_indx]))\n",
    "            f.close()\n",
    "\n",
    "\n",
    "    # resize image and append image and its labels into respective lists\n",
    "    def preprocess(self):\n",
    "        img_lst = []\n",
    "        age_lst = []\n",
    "        mask_lst = []\n",
    "        gender_lst = []\n",
    "        eyewear_lst = []\n",
    "        headwear_lst = []\n",
    "        haircolor_lst = []\n",
    "        hairlength_lst = []\n",
    "        facialhair_lst = []\n",
    "        \n",
    "        img_size = self.img_size\n",
    "        imagePaths = self.shuffle()\n",
    "\n",
    "        for img_path_indx in tqdm(range(len(imagePaths))):\n",
    "            img_path = imagePaths[img_path_indx]\n",
    "\n",
    "            #load image, resize it, convert it to array and append to image list\n",
    "            img = Image.open(img_path)\n",
    "            img = img.resize(img_size)\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            #ensure images are RGB\n",
    "            if img_array.shape == (img_size[1],img_size[0], 3):\n",
    "                img_lst.append(img_array)\n",
    "            else:\n",
    "                #format image to RGB before appending to list\n",
    "                img = self.format_rgb(img) \n",
    "                img_array = np.array(img)\n",
    "                img_lst.append(img_array)                \n",
    "\n",
    "            #extract labels from path name and append to respective label lists\n",
    "            (gender, eyewear, hairlength, facehair, headwear, haircolor, mask, age) = img_path.split(os.path.sep)[-2].split(\"_\")\n",
    "            age_lst.append(age)\n",
    "            mask_lst.append(mask)\n",
    "            gender_lst.append(gender)\n",
    "            eyewear_lst.append(eyewear)\n",
    "            headwear_lst.append(headwear)\n",
    "            facialhair_lst.append(facehair)\n",
    "            haircolor_lst.append(haircolor)\n",
    "            hairlength_lst.append(hairlength)\n",
    "        \n",
    "        #normalize image list\n",
    "        data_array = np.array(img_lst, dtype=np.float32)/255.0\n",
    "        \n",
    "        #convert label lists to numpy array\n",
    "        age_array = np.array(age_lst)\n",
    "        mask_array = np.array(mask_lst)\n",
    "        gender_array = np.array(gender_lst) \n",
    "        eyewear_array = np.array(eyewear_lst) \n",
    "        headwear_array = np.array(headwear_lst) \n",
    "        haircolor_array = np.array(haircolor_lst) \n",
    "        hairlength_array = np.array(hairlength_lst) \n",
    "        facialhair_array = np.array(facialhair_lst)\n",
    "        \n",
    "        #binarize labels\n",
    "        # NOTE: e.g  original list of labels --> [black, black, yellow, green, green, white, ...] \n",
    "        #           unique labels --> [black, green, yellow, white]\n",
    "        #           one-hot encoding --> black = [1,0,0,0], green = [0,1,0,0], etc.\n",
    "        #           new array of binary labels --> [ [1,0,0,0], [1,0,0,0], [0,0,1,0], [0,1,0,0], ....]\n",
    "        \n",
    "        age_binary_labels = LabelBinarizer().fit_transform(age_array)\n",
    "        mask_binary_labels = LabelBinarizer().fit_transform(mask_array)\n",
    "        gender_binary_labels = LabelBinarizer().fit_transform(gender_array)\n",
    "        eyewear_binary_labels = LabelBinarizer().fit_transform(eyewear_array)\n",
    "        headwear_binary_labels = LabelBinarizer().fit_transform(headwear_array)\n",
    "        haircolor_binary_labels = LabelBinarizer().fit_transform(haircolor_array)\n",
    "        hairlength_binary_labels = LabelBinarizer().fit_transform(hairlength_array)\n",
    "        facialhair_binary_labels = LabelBinarizer().fit_transform(facialhair_array)\n",
    "        \n",
    "        return [data_array, gender_binary_labels, eyewear_binary_labels, hairlength_binary_labels, facialhair_binary_labels, headwear_binary_labels, haircolor_binary_labels, mask_binary_labels, age_binary_labels]\n",
    "    \n",
    "    #train-test split data\n",
    "    def data_split(self, save_data = False):\n",
    "        data_lst = data_array, gender_binary_labels, eyewear_binary_labels, hairlength_binary_labels, facialhair_binary_labels, headwear_binary_labels, haircolor_binary_labels, mask_binary_labels, age_binary_labels = self.preprocess()\n",
    "        \n",
    "        if save_data:\n",
    "            self.save_data(data_lst)\n",
    "            print('Data saved \\n')\n",
    "\n",
    "        (train_data, test_data,             # train/test data\n",
    "        train_gender, test_gender,          # train/test gender labels\n",
    "        train_eyewear, test_eyewear,        # train/test eyewear labels\n",
    "        train_hairlength, test_hairlength,  # train/test hairlength labels\n",
    "        train_facialhair, test_facialhair,  # train/test facialhair labels\n",
    "        train_headwear, test_headwear,      # train/test headwear labels\n",
    "        train_haircolor, test_haircolor,    # train/test haircolor labels\n",
    "        train_mask, test_mask,              # train/test mask labels, train/test age labels\n",
    "        train_age, test_age) = train_test_split(data_array,\n",
    "                                                gender_binary_labels, eyewear_binary_labels, hairlength_binary_labels, facialhair_binary_labels, headwear_binary_labels, haircolor_binary_labels, mask_binary_labels, age_binary_labels,\n",
    "                                                test_size=0.2)\n",
    "        print(\"Data Preprocessing Completed\")\n",
    "        return (train_data, test_data, train_gender, test_gender, train_eyewear, test_eyewear, train_hairlength, test_hairlength, train_facialhair, test_facialhair, train_headwear, test_headwear, train_haircolor, test_haircolor, train_mask, test_mask, train_age, test_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55235/55235 [15:20<00:00, 60.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved \n",
      "\n",
      "Data Preprocessing Completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[[0.5372549 , 0.6       , 0.34509805],\n",
       "          [0.5686275 , 0.6313726 , 0.3764706 ],\n",
       "          [0.57254905, 0.63529414, 0.38039216],\n",
       "          ...,\n",
       "          [0.7058824 , 0.7254902 , 0.6509804 ],\n",
       "          [0.7019608 , 0.72156864, 0.6392157 ],\n",
       "          [0.7058824 , 0.7254902 , 0.63529414]],\n",
       " \n",
       "         [[0.54901963, 0.6117647 , 0.3529412 ],\n",
       "          [0.57254905, 0.6392157 , 0.3764706 ],\n",
       "          [0.5686275 , 0.6313726 , 0.37254903],\n",
       "          ...,\n",
       "          [0.70980394, 0.7294118 , 0.654902  ],\n",
       "          [0.7058824 , 0.7254902 , 0.6431373 ],\n",
       "          [0.70980394, 0.7294118 , 0.6392157 ]],\n",
       " \n",
       "         [[0.58431375, 0.6431373 , 0.3764706 ],\n",
       "          [0.59607846, 0.654902  , 0.38431373],\n",
       "          [0.5411765 , 0.6       , 0.33333334],\n",
       "          ...,\n",
       "          [0.69803923, 0.72156864, 0.65882355],\n",
       "          [0.6901961 , 0.72156864, 0.63529414],\n",
       "          [0.6901961 , 0.72156864, 0.627451  ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.07058824, 0.07450981, 0.01960784],\n",
       "          [0.14901961, 0.15686275, 0.10196079],\n",
       "          [0.13725491, 0.14901961, 0.09803922],\n",
       "          ...,\n",
       "          [0.50980395, 0.5254902 , 0.2901961 ],\n",
       "          [0.58431375, 0.60784316, 0.3647059 ],\n",
       "          [0.5647059 , 0.5882353 , 0.34509805]],\n",
       " \n",
       "         [[0.03921569, 0.04313726, 0.01176471],\n",
       "          [0.10588235, 0.10980392, 0.08627451],\n",
       "          [0.09411765, 0.09803922, 0.07450981],\n",
       "          ...,\n",
       "          [0.77254903, 0.7490196 , 0.5568628 ],\n",
       "          [0.80784315, 0.78431374, 0.5882353 ],\n",
       "          [0.8       , 0.7764706 , 0.5803922 ]],\n",
       " \n",
       "         [[0.04705882, 0.05098039, 0.03137255],\n",
       "          [0.08627451, 0.09411765, 0.07450981],\n",
       "          [0.09411765, 0.10196079, 0.08627451],\n",
       "          ...,\n",
       "          [0.84313726, 0.8       , 0.62352943],\n",
       "          [0.827451  , 0.78431374, 0.60784316],\n",
       "          [0.827451  , 0.78431374, 0.60784316]]],\n",
       " \n",
       " \n",
       "        [[[0.5921569 , 0.627451  , 0.4117647 ],\n",
       "          [0.34901962, 0.39607844, 0.16470589],\n",
       "          [0.41960785, 0.48235294, 0.22745098],\n",
       "          ...,\n",
       "          [0.50980395, 0.49411765, 0.4862745 ],\n",
       "          [0.45882353, 0.44313726, 0.43137255],\n",
       "          [0.4509804 , 0.4392157 , 0.41960785]],\n",
       " \n",
       "         [[0.39607844, 0.43529412, 0.2       ],\n",
       "          [0.24313726, 0.29411766, 0.05098039],\n",
       "          [0.7529412 , 0.81960785, 0.54509807],\n",
       "          ...,\n",
       "          [0.52156866, 0.50980395, 0.49019608],\n",
       "          [0.45490196, 0.44313726, 0.41568628],\n",
       "          [0.44313726, 0.43137255, 0.40392157]],\n",
       " \n",
       "         [[0.4392157 , 0.4745098 , 0.22352941],\n",
       "          [0.14901961, 0.19215687, 0.03137255],\n",
       "          [0.5803922 , 0.64705884, 0.3372549 ],\n",
       "          ...,\n",
       "          [0.6392157 , 0.6313726 , 0.5921569 ],\n",
       "          [0.5372549 , 0.5294118 , 0.48235294],\n",
       "          [0.52156866, 0.5137255 , 0.4627451 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.2627451 , 0.23137255, 0.1882353 ],\n",
       "          [0.20784314, 0.1764706 , 0.13333334],\n",
       "          [0.21960784, 0.1882353 , 0.14509805],\n",
       "          ...,\n",
       "          [0.9607843 , 0.92941177, 0.90588236],\n",
       "          [1.        , 0.98039216, 0.9843137 ],\n",
       "          [1.        , 0.9843137 , 1.        ]],\n",
       " \n",
       "         [[0.21176471, 0.1882353 , 0.14117648],\n",
       "          [0.34509805, 0.32156864, 0.27450982],\n",
       "          [0.96862745, 0.9647059 , 0.9254902 ],\n",
       "          ...,\n",
       "          [0.94509804, 0.92156863, 0.90588236],\n",
       "          [0.99607843, 0.972549  , 0.9764706 ],\n",
       "          [0.99215686, 0.96862745, 0.9843137 ]],\n",
       " \n",
       "         [[0.7607843 , 0.74509805, 0.7019608 ],\n",
       "          [0.79607844, 0.78039217, 0.7372549 ],\n",
       "          [1.        , 1.        , 0.95686275],\n",
       "          ...,\n",
       "          [0.6901961 , 0.6745098 , 0.6627451 ],\n",
       "          [0.79607844, 0.78039217, 0.78039217],\n",
       "          [0.8392157 , 0.81960785, 0.8352941 ]]],\n",
       " \n",
       " \n",
       "        [[[0.7019608 , 0.69411767, 0.7137255 ],\n",
       "          [0.7019608 , 0.69411767, 0.7137255 ],\n",
       "          [0.7019608 , 0.69411767, 0.7137255 ],\n",
       "          ...,\n",
       "          [0.7176471 , 0.72156864, 0.7372549 ],\n",
       "          [0.72156864, 0.7176471 , 0.7372549 ],\n",
       "          [0.72156864, 0.7176471 , 0.7372549 ]],\n",
       " \n",
       "         [[0.7019608 , 0.69411767, 0.7137255 ],\n",
       "          [0.7019608 , 0.69411767, 0.7137255 ],\n",
       "          [0.7019608 , 0.69411767, 0.7137255 ],\n",
       "          ...,\n",
       "          [0.7176471 , 0.72156864, 0.7372549 ],\n",
       "          [0.72156864, 0.7176471 , 0.7372549 ],\n",
       "          [0.72156864, 0.7176471 , 0.7372549 ]],\n",
       " \n",
       "         [[0.7019608 , 0.69411767, 0.7137255 ],\n",
       "          [0.7019608 , 0.69411767, 0.7137255 ],\n",
       "          [0.7019608 , 0.69411767, 0.7137255 ],\n",
       "          ...,\n",
       "          [0.7176471 , 0.72156864, 0.73333335],\n",
       "          [0.72156864, 0.7176471 , 0.7372549 ],\n",
       "          [0.72156864, 0.7176471 , 0.7372549 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.8392157 , 0.14117648, 0.18431373],\n",
       "          [0.84313726, 0.14509805, 0.1882353 ],\n",
       "          [0.8509804 , 0.14901961, 0.19607843],\n",
       "          ...,\n",
       "          [0.8901961 , 0.6901961 , 0.60784316],\n",
       "          [0.89411765, 0.6666667 , 0.5921569 ],\n",
       "          [0.83137256, 0.58431375, 0.5176471 ]],\n",
       " \n",
       "         [[0.827451  , 0.14509805, 0.2       ],\n",
       "          [0.8235294 , 0.14117648, 0.19607843],\n",
       "          [0.83137256, 0.14117648, 0.19607843],\n",
       "          ...,\n",
       "          [0.89411765, 0.6901961 , 0.60784316],\n",
       "          [0.8901961 , 0.6745098 , 0.59607846],\n",
       "          [0.8901961 , 0.6745098 , 0.59607846]],\n",
       " \n",
       "         [[0.83137256, 0.16470589, 0.21568628],\n",
       "          [0.8235294 , 0.14901961, 0.20392157],\n",
       "          [0.8235294 , 0.13725491, 0.19607843],\n",
       "          ...,\n",
       "          [0.8627451 , 0.64705884, 0.5764706 ],\n",
       "          [0.9372549 , 0.73333335, 0.6509804 ],\n",
       "          [0.8862745 , 0.68235296, 0.6       ]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0.39215687, 0.3137255 , 0.28235295],\n",
       "          [0.39215687, 0.3137255 , 0.28235295],\n",
       "          [0.39215687, 0.3137255 , 0.28235295],\n",
       "          ...,\n",
       "          [0.6745098 , 0.6       , 0.52156866],\n",
       "          [0.6745098 , 0.6       , 0.5137255 ],\n",
       "          [0.6745098 , 0.6039216 , 0.5058824 ]],\n",
       " \n",
       "         [[0.37254903, 0.31764707, 0.28627452],\n",
       "          [0.37254903, 0.31764707, 0.28627452],\n",
       "          [0.37254903, 0.31764707, 0.28627452],\n",
       "          ...,\n",
       "          [0.6509804 , 0.6       , 0.54509807],\n",
       "          [0.6509804 , 0.6       , 0.5411765 ],\n",
       "          [0.6509804 , 0.6       , 0.5372549 ]],\n",
       " \n",
       "         [[0.32941177, 0.29411766, 0.2784314 ],\n",
       "          [0.32941177, 0.29803923, 0.28235295],\n",
       "          [0.32941177, 0.29803923, 0.28235295],\n",
       "          ...,\n",
       "          [0.53333336, 0.50980395, 0.49411765],\n",
       "          [0.53333336, 0.50980395, 0.49019608],\n",
       "          [0.53333336, 0.50980395, 0.49019608]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.14509805, 0.15686275, 0.16078432],\n",
       "          [0.16470589, 0.17254902, 0.18039216],\n",
       "          [0.18431373, 0.19607843, 0.2       ],\n",
       "          ...,\n",
       "          [0.76862746, 0.7607843 , 0.78039217],\n",
       "          [0.76862746, 0.7607843 , 0.78039217],\n",
       "          [0.76862746, 0.7607843 , 0.78039217]],\n",
       " \n",
       "         [[0.15686275, 0.15686275, 0.16470589],\n",
       "          [0.16470589, 0.16862746, 0.1764706 ],\n",
       "          [0.18039216, 0.18039216, 0.1882353 ],\n",
       "          ...,\n",
       "          [0.7647059 , 0.7607843 , 0.78039217],\n",
       "          [0.77254903, 0.7647059 , 0.78431374],\n",
       "          [0.77254903, 0.7647059 , 0.78431374]],\n",
       " \n",
       "         [[0.16862746, 0.16470589, 0.1764706 ],\n",
       "          [0.16862746, 0.16470589, 0.17254902],\n",
       "          [0.15686275, 0.15294118, 0.16470589],\n",
       "          ...,\n",
       "          [0.7607843 , 0.74509805, 0.7607843 ],\n",
       "          [0.77254903, 0.75686276, 0.77254903],\n",
       "          [0.78039217, 0.7647059 , 0.78039217]]],\n",
       " \n",
       " \n",
       "        [[[0.        , 0.        , 0.00784314],\n",
       "          [0.00392157, 0.00392157, 0.01176471],\n",
       "          [0.        , 0.        , 0.00784314],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.        , 0.00392157],\n",
       "          [0.00392157, 0.00392157, 0.00784314],\n",
       "          [0.        , 0.        , 0.00392157],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       " \n",
       "         [[0.00392157, 0.00392157, 0.        ],\n",
       "          [0.00392157, 0.00392157, 0.00392157],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]]],\n",
       " \n",
       " \n",
       "        [[[0.54509807, 0.54901963, 0.5176471 ],\n",
       "          [0.5686275 , 0.5764706 , 0.5294118 ],\n",
       "          [0.5568628 , 0.5647059 , 0.5058824 ],\n",
       "          ...,\n",
       "          [0.7294118 , 0.7372549 , 0.69411767],\n",
       "          [0.73333335, 0.7411765 , 0.69803923],\n",
       "          [0.73333335, 0.7411765 , 0.69803923]],\n",
       " \n",
       "         [[0.5254902 , 0.5294118 , 0.49803922],\n",
       "          [0.5137255 , 0.52156866, 0.4745098 ],\n",
       "          [0.5686275 , 0.5764706 , 0.50980395],\n",
       "          ...,\n",
       "          [0.72156864, 0.7294118 , 0.6901961 ],\n",
       "          [0.7254902 , 0.7294118 , 0.69803923],\n",
       "          [0.7254902 , 0.73333335, 0.6901961 ]],\n",
       " \n",
       "         [[0.5254902 , 0.53333336, 0.49019608],\n",
       "          [0.5176471 , 0.5254902 , 0.4745098 ],\n",
       "          [0.5568628 , 0.5686275 , 0.49411765],\n",
       "          ...,\n",
       "          [0.69411767, 0.69803923, 0.67058825],\n",
       "          [0.69411767, 0.69803923, 0.6745098 ],\n",
       "          [0.69411767, 0.69803923, 0.6666667 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.1254902 , 0.13725491, 0.15686275],\n",
       "          [0.12941177, 0.14117648, 0.16078432],\n",
       "          [0.13333334, 0.14509805, 0.16470589],\n",
       "          ...,\n",
       "          [0.13333334, 0.12941177, 0.12156863],\n",
       "          [0.13333334, 0.12941177, 0.12156863],\n",
       "          [0.13333334, 0.12941177, 0.12156863]],\n",
       " \n",
       "         [[0.1254902 , 0.13725491, 0.15686275],\n",
       "          [0.12941177, 0.14117648, 0.16078432],\n",
       "          [0.13333334, 0.14509805, 0.16470589],\n",
       "          ...,\n",
       "          [0.13333334, 0.12941177, 0.12156863],\n",
       "          [0.13333334, 0.12941177, 0.12156863],\n",
       "          [0.13333334, 0.12941177, 0.12156863]],\n",
       " \n",
       "         [[0.1254902 , 0.13725491, 0.15686275],\n",
       "          [0.12941177, 0.14117648, 0.16078432],\n",
       "          [0.13333334, 0.14509805, 0.16470589],\n",
       "          ...,\n",
       "          [0.13333334, 0.12941177, 0.12156863],\n",
       "          [0.13333334, 0.12941177, 0.12156863],\n",
       "          [0.13333334, 0.12941177, 0.12156863]]]], dtype=float32),\n",
       " array([[[[0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.42352942, 0.4117647 , 0.4117647 ],\n",
       "          [0.30588236, 0.3019608 , 0.29411766],\n",
       "          [0.16470589, 0.16078432, 0.15294118]],\n",
       " \n",
       "         [[0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.34509805, 0.33333334, 0.33333334],\n",
       "          [0.18431373, 0.1764706 , 0.1764706 ],\n",
       "          [0.03529412, 0.03137255, 0.02745098]],\n",
       " \n",
       "         [[0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.26666668, 0.25490198, 0.25490198],\n",
       "          [0.0627451 , 0.05882353, 0.0627451 ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.30980393, 0.28235295, 0.24313726],\n",
       "          [0.46666667, 0.44313726, 0.4       ],\n",
       "          [0.45882353, 0.4392157 , 0.39607844],\n",
       "          ...,\n",
       "          [0.03921569, 0.00784314, 0.        ],\n",
       "          [0.03137255, 0.00392157, 0.00392157],\n",
       "          [0.02745098, 0.        , 0.        ]],\n",
       " \n",
       "         [[0.27058825, 0.25882354, 0.22745098],\n",
       "          [0.47058824, 0.45882353, 0.42745098],\n",
       "          [0.4627451 , 0.4509804 , 0.42352942],\n",
       "          ...,\n",
       "          [0.00392157, 0.00784314, 0.00392157],\n",
       "          [0.00784314, 0.00392157, 0.00392157],\n",
       "          [0.01176471, 0.00784314, 0.00784314]],\n",
       " \n",
       "         [[0.25882354, 0.25882354, 0.22745098],\n",
       "          [0.47058824, 0.46666667, 0.43529412],\n",
       "          [0.45882353, 0.45490196, 0.43137255],\n",
       "          ...,\n",
       "          [0.        , 0.01176471, 0.01176471],\n",
       "          [0.        , 0.00784314, 0.00392157],\n",
       "          [0.        , 0.00784314, 0.00392157]]],\n",
       " \n",
       " \n",
       "        [[[0.49803922, 0.44313726, 0.4       ],\n",
       "          [0.49411765, 0.4509804 , 0.40392157],\n",
       "          [0.48235294, 0.4627451 , 0.40784314],\n",
       "          ...,\n",
       "          [0.24705882, 0.21176471, 0.22352941],\n",
       "          [0.23921569, 0.20392157, 0.21568628],\n",
       "          [0.24705882, 0.21176471, 0.22352941]],\n",
       " \n",
       "         [[0.52156866, 0.46666667, 0.42745098],\n",
       "          [0.5058824 , 0.46666667, 0.41568628],\n",
       "          [0.4862745 , 0.46666667, 0.4117647 ],\n",
       "          ...,\n",
       "          [0.24313726, 0.20784314, 0.21960784],\n",
       "          [0.23921569, 0.20392157, 0.21568628],\n",
       "          [0.24313726, 0.20784314, 0.21960784]],\n",
       " \n",
       "         [[0.56078434, 0.5137255 , 0.47843137],\n",
       "          [0.5176471 , 0.48235294, 0.44313726],\n",
       "          [0.52156866, 0.5019608 , 0.45490196],\n",
       "          ...,\n",
       "          [0.24313726, 0.20784314, 0.21960784],\n",
       "          [0.23921569, 0.20392157, 0.21568628],\n",
       "          [0.24313726, 0.20784314, 0.21960784]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.6666667 , 0.73333335, 0.5921569 ],\n",
       "          [0.6901961 , 0.7529412 , 0.6117647 ],\n",
       "          [0.69411767, 0.74509805, 0.60784316],\n",
       "          ...,\n",
       "          [0.7411765 , 0.28627452, 0.3882353 ],\n",
       "          [0.7921569 , 0.29411766, 0.4117647 ],\n",
       "          [0.7882353 , 0.2627451 , 0.39215687]],\n",
       " \n",
       "         [[0.6666667 , 0.73333335, 0.5921569 ],\n",
       "          [0.6862745 , 0.7490196 , 0.60784316],\n",
       "          [0.69411767, 0.74509805, 0.6039216 ],\n",
       "          ...,\n",
       "          [0.7372549 , 0.28627452, 0.3882353 ],\n",
       "          [0.7882353 , 0.29411766, 0.4117647 ],\n",
       "          [0.7882353 , 0.2627451 , 0.39215687]],\n",
       " \n",
       "         [[0.6666667 , 0.73333335, 0.5921569 ],\n",
       "          [0.6862745 , 0.7490196 , 0.60784316],\n",
       "          [0.69411767, 0.74509805, 0.6039216 ],\n",
       "          ...,\n",
       "          [0.7372549 , 0.28627452, 0.3882353 ],\n",
       "          [0.7882353 , 0.29411766, 0.4117647 ],\n",
       "          [0.7882353 , 0.2627451 , 0.39215687]]],\n",
       " \n",
       " \n",
       "        [[[0.05882353, 0.05490196, 0.04705882],\n",
       "          [0.08235294, 0.07843138, 0.07058824],\n",
       "          [0.13725491, 0.12941177, 0.11372549],\n",
       "          ...,\n",
       "          [0.08235294, 0.07843138, 0.07058824],\n",
       "          [0.08627451, 0.08235294, 0.07450981],\n",
       "          [0.09019608, 0.08627451, 0.07843138]],\n",
       " \n",
       "         [[0.05882353, 0.05490196, 0.04705882],\n",
       "          [0.06666667, 0.06666667, 0.05882353],\n",
       "          [0.09803922, 0.09411765, 0.08235294],\n",
       "          ...,\n",
       "          [0.08235294, 0.07843138, 0.07058824],\n",
       "          [0.08627451, 0.08235294, 0.07450981],\n",
       "          [0.09803922, 0.09411765, 0.08627451]],\n",
       " \n",
       "         [[0.05882353, 0.05490196, 0.04705882],\n",
       "          [0.06666667, 0.0627451 , 0.05490196],\n",
       "          [0.08235294, 0.07450981, 0.07058824],\n",
       "          ...,\n",
       "          [0.08627451, 0.08235294, 0.07450981],\n",
       "          [0.08627451, 0.08235294, 0.07450981],\n",
       "          [0.09411765, 0.09019608, 0.08235294]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.13725491, 0.14901961, 0.18039216],\n",
       "          [0.12941177, 0.13725491, 0.16078432],\n",
       "          [0.12156863, 0.1254902 , 0.14901961],\n",
       "          ...,\n",
       "          [0.14117648, 0.15294118, 0.18431373],\n",
       "          [0.15294118, 0.16470589, 0.19607843],\n",
       "          [0.15294118, 0.16470589, 0.2       ]],\n",
       " \n",
       "         [[0.11764706, 0.12941177, 0.15686275],\n",
       "          [0.12941177, 0.13333334, 0.15294118],\n",
       "          [0.12941177, 0.13333334, 0.15294118],\n",
       "          ...,\n",
       "          [0.12941177, 0.13725491, 0.1882353 ],\n",
       "          [0.14509805, 0.15294118, 0.2       ],\n",
       "          [0.14509805, 0.15294118, 0.19607843]],\n",
       " \n",
       "         [[0.11764706, 0.12941177, 0.15686275],\n",
       "          [0.11764706, 0.1254902 , 0.14901961],\n",
       "          [0.1254902 , 0.12941177, 0.14901961],\n",
       "          ...,\n",
       "          [0.14117648, 0.14901961, 0.19607843],\n",
       "          [0.14901961, 0.16078432, 0.2       ],\n",
       "          [0.14901961, 0.15686275, 0.19607843]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0.38431373, 0.41960785, 0.29803923],\n",
       "          [0.4       , 0.43529412, 0.32156864],\n",
       "          [0.4627451 , 0.49803922, 0.3882353 ],\n",
       "          ...,\n",
       "          [0.36078432, 0.40784314, 0.21176471],\n",
       "          [0.3882353 , 0.43529412, 0.23921569],\n",
       "          [0.4       , 0.44705883, 0.2509804 ]],\n",
       " \n",
       "         [[0.5568628 , 0.5921569 , 0.47058824],\n",
       "          [0.42352942, 0.45882353, 0.34509805],\n",
       "          [0.33333334, 0.36862746, 0.25882354],\n",
       "          ...,\n",
       "          [0.34509805, 0.39215687, 0.19607843],\n",
       "          [0.3529412 , 0.4       , 0.20392157],\n",
       "          [0.35686275, 0.40392157, 0.20784314]],\n",
       " \n",
       "         [[0.6509804 , 0.6901961 , 0.56078434],\n",
       "          [0.62352943, 0.65882355, 0.5372549 ],\n",
       "          [0.58431375, 0.61960787, 0.5019608 ],\n",
       "          ...,\n",
       "          [0.3529412 , 0.4       , 0.20392157],\n",
       "          [0.3529412 , 0.4       , 0.20392157],\n",
       "          [0.3529412 , 0.4       , 0.20392157]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.67058825, 0.67058825, 0.70980394],\n",
       "          [0.6627451 , 0.6627451 , 0.7019608 ],\n",
       "          [0.6392157 , 0.6392157 , 0.6784314 ],\n",
       "          ...,\n",
       "          [0.6313726 , 0.63529414, 0.6509804 ],\n",
       "          [0.6313726 , 0.63529414, 0.6509804 ],\n",
       "          [0.6313726 , 0.63529414, 0.6509804 ]],\n",
       " \n",
       "         [[0.6156863 , 0.6156863 , 0.654902  ],\n",
       "          [0.6117647 , 0.6117647 , 0.6509804 ],\n",
       "          [0.60784316, 0.60784316, 0.64705884],\n",
       "          ...,\n",
       "          [0.63529414, 0.6392157 , 0.654902  ],\n",
       "          [0.63529414, 0.6392157 , 0.654902  ],\n",
       "          [0.63529414, 0.6392157 , 0.654902  ]],\n",
       " \n",
       "         [[0.59607846, 0.59607846, 0.63529414],\n",
       "          [0.6       , 0.6       , 0.6392157 ],\n",
       "          [0.6039216 , 0.6039216 , 0.6431373 ],\n",
       "          ...,\n",
       "          [0.63529414, 0.6392157 , 0.64705884],\n",
       "          [0.63529414, 0.63529414, 0.64705884],\n",
       "          [0.6392157 , 0.6392157 , 0.6509804 ]]],\n",
       " \n",
       " \n",
       "        [[[0.22352941, 0.25490198, 0.21176471],\n",
       "          [0.2509804 , 0.28627452, 0.23137255],\n",
       "          [0.07058824, 0.10980392, 0.05098039],\n",
       "          ...,\n",
       "          [0.40784314, 0.42352942, 0.43529412],\n",
       "          [0.42352942, 0.43529412, 0.44705883],\n",
       "          [0.41568628, 0.41960785, 0.43529412]],\n",
       " \n",
       "         [[0.24313726, 0.27058825, 0.25490198],\n",
       "          [0.24313726, 0.26666668, 0.24705882],\n",
       "          [0.09803922, 0.1254902 , 0.10196079],\n",
       "          ...,\n",
       "          [0.43529412, 0.4509804 , 0.4627451 ],\n",
       "          [0.4392157 , 0.4509804 , 0.4627451 ],\n",
       "          [0.41568628, 0.41960785, 0.43529412]],\n",
       " \n",
       "         [[0.23921569, 0.27450982, 0.21960784],\n",
       "          [0.21960784, 0.2509804 , 0.2       ],\n",
       "          [0.14509805, 0.17254902, 0.13725491],\n",
       "          ...,\n",
       "          [0.40392157, 0.41960785, 0.43137255],\n",
       "          [0.39215687, 0.4       , 0.41568628],\n",
       "          [0.37254903, 0.3764706 , 0.39215687]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.5764706 , 0.53333336, 0.45490196],\n",
       "          [0.56078434, 0.5176471 , 0.4392157 ],\n",
       "          [0.56078434, 0.5176471 , 0.4392157 ],\n",
       "          ...,\n",
       "          [0.5294118 , 0.5137255 , 0.46666667],\n",
       "          [0.48235294, 0.4627451 , 0.41568628],\n",
       "          [0.42352942, 0.4       , 0.3529412 ]],\n",
       " \n",
       "         [[0.5176471 , 0.4745098 , 0.39607844],\n",
       "          [0.49411765, 0.4509804 , 0.37254903],\n",
       "          [0.49803922, 0.45490196, 0.3764706 ],\n",
       "          ...,\n",
       "          [0.5019608 , 0.48235294, 0.43137255],\n",
       "          [0.5137255 , 0.49019608, 0.43529412],\n",
       "          [0.47058824, 0.44705883, 0.39215687]],\n",
       " \n",
       "         [[0.5803922 , 0.5372549 , 0.45882353],\n",
       "          [0.62352943, 0.5803922 , 0.5019608 ],\n",
       "          [0.5921569 , 0.54901963, 0.47058824],\n",
       "          ...,\n",
       "          [0.59607846, 0.5764706 , 0.5294118 ],\n",
       "          [0.54509807, 0.52156866, 0.47058824],\n",
       "          [0.49803922, 0.4745098 , 0.41960785]]],\n",
       " \n",
       " \n",
       "        [[[0.1882353 , 0.22352941, 0.14901961],\n",
       "          [0.1764706 , 0.21176471, 0.13725491],\n",
       "          [0.1764706 , 0.21176471, 0.13725491],\n",
       "          ...,\n",
       "          [0.32941177, 0.3647059 , 0.29803923],\n",
       "          [0.4117647 , 0.44705883, 0.38039216],\n",
       "          [0.38431373, 0.41960785, 0.3529412 ]],\n",
       " \n",
       "         [[0.20392157, 0.23921569, 0.16470589],\n",
       "          [0.18431373, 0.21960784, 0.14509805],\n",
       "          [0.17254902, 0.20784314, 0.13333334],\n",
       "          ...,\n",
       "          [0.22352941, 0.25882354, 0.19215687],\n",
       "          [0.36078432, 0.39607844, 0.32941177],\n",
       "          [0.42745098, 0.4627451 , 0.39607844]],\n",
       " \n",
       "         [[0.20784314, 0.24313726, 0.16862746],\n",
       "          [0.19607843, 0.23137255, 0.15686275],\n",
       "          [0.18431373, 0.21960784, 0.14509805],\n",
       "          ...,\n",
       "          [0.12941177, 0.16470589, 0.09803922],\n",
       "          [0.3019608 , 0.3372549 , 0.27058825],\n",
       "          [0.43529412, 0.47058824, 0.40392157]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.18431373, 0.1882353 , 0.15686275],\n",
       "          [0.1764706 , 0.18039216, 0.14901961],\n",
       "          [0.1764706 , 0.18039216, 0.15294118],\n",
       "          ...,\n",
       "          [0.13725491, 0.14117648, 0.14901961],\n",
       "          [0.14117648, 0.14509805, 0.15294118],\n",
       "          [0.14901961, 0.15294118, 0.16078432]],\n",
       " \n",
       "         [[0.18431373, 0.1882353 , 0.15686275],\n",
       "          [0.18431373, 0.1882353 , 0.15686275],\n",
       "          [0.18039216, 0.18431373, 0.15686275],\n",
       "          ...,\n",
       "          [0.14117648, 0.14509805, 0.15294118],\n",
       "          [0.14117648, 0.14509805, 0.15294118],\n",
       "          [0.14901961, 0.15294118, 0.16078432]],\n",
       " \n",
       "         [[0.18431373, 0.1882353 , 0.15686275],\n",
       "          [0.1882353 , 0.19215687, 0.16078432],\n",
       "          [0.18431373, 0.1882353 , 0.16078432],\n",
       "          ...,\n",
       "          [0.14509805, 0.14901961, 0.15686275],\n",
       "          [0.14509805, 0.14901961, 0.15686275],\n",
       "          [0.15294118, 0.15686275, 0.16470589]]]], dtype=float32),\n",
       " array([[1],\n",
       "        [1],\n",
       "        [0],\n",
       "        ...,\n",
       "        [1],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [1],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[1, 0, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [1, 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 1, 0, 0]]),\n",
       " array([[0, 1, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        ...,\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 0, 0, 1]]),\n",
       " array([[0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 1, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0]]),\n",
       " array([[0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0],\n",
       "        ...,\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0]]),\n",
       " array([[0, 0, 1, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 1, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 1, 0]]),\n",
       " array([[0, 0, 1, 0],\n",
       "        [0, 0, 1, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        ...,\n",
       "        [0, 0, 1, 0],\n",
       "        [0, 0, 1, 0],\n",
       "        [0, 0, 0, 1]]),\n",
       " array([[0, 0, 0, ..., 0, 1, 0],\n",
       "        [0, 0, 0, ..., 0, 1, 0],\n",
       "        [0, 0, 0, ..., 0, 1, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 1, 0],\n",
       "        [0, 0, 0, ..., 0, 1, 0],\n",
       "        [0, 0, 0, ..., 0, 1, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 1, 0],\n",
       "        [0, 0, 0, ..., 0, 1, 0],\n",
       "        [0, 0, 0, ..., 0, 1, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 1, 0],\n",
       "        [0, 0, 0, ..., 0, 1, 0],\n",
       "        [0, 0, 0, ..., 0, 1, 0]]),\n",
       " array([[1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        ...,\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0]]),\n",
       " array([[0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        ...,\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1]]),\n",
       " array([[0, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0]]),\n",
       " array([[0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, 0, 1, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = r\"D:\\Daniel\\research\\PA-Head_Dataset\"\n",
    "img_size = (96,96)\n",
    "generator = DataGenerator(attribute_info)\n",
    "items = generator.data_split(save_data=True)\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# Build Multi-Output Model #\n",
    "############################\n",
    "class MultiOutputModel():\n",
    "    #Different Head Attributes: Gender, Age, Head accessories, Hair Type(long,short,etc.), Hair Color, Eye accessories, Mouth accessories, Facial Hair\n",
    "    #Approach: split color-dependent entities and non-color entities into 2 different CNN branches\n",
    "        # Branch 1: ResNet50 --> for hair colour\n",
    "        # Branch 2: DenseNet201 --> for head, eye, and mouth accessories [fabrics] (distinguished by shapes, sizes and textures)\n",
    "        # Branch 3: ResNet101 --> for gender, age, facial hair [human-features]\n",
    "    \n",
    "    ##################\n",
    "    # Initialisation #\n",
    "    ##################\n",
    "    def __init__(self, attribute_info, processed_data=None, model_path=None):\n",
    "\n",
    "        #verify information of attribute_info dictionary\n",
    "        try:\n",
    "            attribute_info['attributes']\n",
    "            attribute_info['image size']\n",
    "            \n",
    "            if processed_data:\n",
    "                attribute_info['weights dir']\n",
    "                attribute_info['logs dir']\n",
    "                attribute_info['loss']\n",
    "                attribute_info['loss weights']\n",
    "                attribute_info['metrics']\n",
    "\n",
    "            self.attribute_info = attribute_info\n",
    "\n",
    "        except Exception as e:\n",
    "            print('Attribute dictionary is not valid')\n",
    "\n",
    "        #function to one-hot encode binary variable: due to tensorflow error for (None,2) when given (None,1) \n",
    "        def verify_encoding(labels):\n",
    "            labels = list(labels)\n",
    "            for label_array_indx in range(len(labels)):\n",
    "                label_array = labels[label_array_indx]\n",
    "                if len(label_array[0])==1: #e.g [0] or [1] --> [1,0] or [0,1]\n",
    "                    new_label_array = np.hstack((1-label_array, label_array))\n",
    "                    labels[label_array_indx] = new_label_array\n",
    "            return tuple(labels)\n",
    "\n",
    "        #initialize variables for training model\n",
    "        if processed_data:\n",
    "\n",
    "            #get attributes from attribute_info dictionary\n",
    "            attributes = [attribute + \"_output\" for attribute in list(attribute_info['attributes'].keys())]\n",
    "\n",
    "            #get train and test data\n",
    "            self.train_data, self.test_data = processed_data[:2]\n",
    "\n",
    "            #make train/test labels dictionaries\n",
    "            train_labels = verify_encoding(processed_data[2::2])\n",
    "            test_labels = verify_encoding(processed_data[3::2])\n",
    "\n",
    "            self.train_labels_dict = dict(zip(attributes, train_labels))\n",
    "            self.test_labels_dict = dict(zip(attributes, test_labels))\n",
    "\n",
    "\n",
    "            #get model compilation information\n",
    "            self.loss_dict = attribute_info['loss']\n",
    "            self.loss_weights_dict = attribute_info['loss weights']\n",
    "            self.metrics_dict = attribute_info['metrics']\n",
    "\n",
    "            #Configure GPU device\n",
    "            os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "            os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "    \n",
    "\n",
    "        #load trained model (for inference)\n",
    "        if model_path:\n",
    "            print(\"Loading model...\")\n",
    "\n",
    "            self.model = load_model(model_path)\n",
    "\n",
    "            print(\"Model sucessfully loaded\")\n",
    "    \n",
    "    ##########################\n",
    "    # Grayscale Conv2D Layer #\n",
    "    ##########################\n",
    "    def build_conv_grayscale_layer(self, branch_name):\n",
    "        #NOTE: this layer converts 3-channel array (RGB) into 1-channel array (grayscale)\n",
    "        # (m, height, width, 3)--> (m, height, width, 1)\n",
    "\n",
    "        \n",
    "        #formula for grayscale image: 0.299R + 0.587G + 0.114B\n",
    "        weights = np.array([[[[ 0.299],\n",
    "                            [0.587 ],\n",
    "                            [0.114]]]], dtype='float32')\n",
    "        \n",
    "        #construct conv layer with specified weights\n",
    "        conv_layer = Conv2D(1, kernel_size=(1, 1),kernel_initializer=tf.keras.initializers.Constant(value=weights), activation=None,use_bias=True,name=f'conv1_convert_grayscale_{branch_name}')\n",
    "        conv_layer.trainable = False\n",
    "        \n",
    "        return conv_layer\n",
    "\n",
    "    ########################################\n",
    "    # Fully Connected Layer (Output Layer) #\n",
    "    ########################################\n",
    "    def build_fully_connected_layer(self, input_tensor, num_classes, branch_id):\n",
    "        if num_classes<=2:\n",
    "            activation = 'sigmoid' #binary classifier\n",
    "        else:\n",
    "            activation = 'softmax' #multi-class classifier\n",
    "        \n",
    "        x = Flatten()(input_tensor)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(64, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(num_classes, activation = activation, name= f'{branch_id}_output')(x)\n",
    "        return x\n",
    "    \n",
    "    ##############################################\n",
    "    # First CNN Branch (Colour-related features) #\n",
    "    ##############################################\n",
    "    def build_color_branch(self, input_tensor):\n",
    "        #initialise base model\n",
    "        base_model = ResNet50(input_tensor = input_tensor, include_top=False, weights='imagenet')\n",
    "        \n",
    "        base_model.trainable = True\n",
    "\n",
    "        x = base_model.output\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    ###################################################\n",
    "    # Second CNN Branch (Non-colour-related features) #\n",
    "    ###################################################\n",
    "    def build_fabric_branch(self, input_tensor, uff_model = True):\n",
    "        if uff_model: \n",
    "            #build grayscale conv layer\n",
    "            grayscale_conv_layer = self.build_conv_grayscale_layer('fabric')\n",
    "            new_input_tensor = grayscale_conv_layer(input_tensor)\n",
    "            \n",
    "            #initialise base model\n",
    "            img_width, img_height = self.attribute_info['image size']\n",
    "            base_model = DenseNet201(input_tensor = Input((img_width, img_height,1)), include_top=False, weights=None)(new_input_tensor)\n",
    "\n",
    "            #let each layer in model to be trainable\n",
    "            base_model.trainable = True\n",
    "\n",
    "            # x = base_model.output\n",
    "            x = base_model\n",
    "            \n",
    "            return x\n",
    "\n",
    "        else: #Lambda layers are only usable in non-uff format\n",
    "            #convert 3-channel input to a grayscale input using Tensorflow Lambda layer\n",
    "            input_tensor = Lambda(lambda c: tf.image.rgb_to_grayscale(c))(input_tensor)\n",
    "\n",
    "            #base model is trained on RGB images (3 channels) --> make grayscale input into 3 channels\n",
    "            input_tensor = Conv2D(3, (3,3), padding ='same')(input_tensor)\n",
    "\n",
    "            #initialise base model\n",
    "            base_model = DenseNet201(include_top=False, weights='imagenet')\n",
    "            \n",
    "            #let each layer in base model to be trainable\n",
    "            base_model.trainable = True \n",
    "\n",
    "            #output base model after feeding 3-channel input: we cannot use model(input_tensor=input_tensor) due to additional conv2d layer that makes the model not compatible: initial n-layer NN becomes (n+1)-layer NN\n",
    "            x = base_model(input_tensor)\n",
    "            \n",
    "            return x\n",
    "    \n",
    "    ##################################################\n",
    "    # Third CNN Branch (Non-colour-related features) #\n",
    "    ##################################################\n",
    "    def build_face_branch(self, input_tensor, uff_model = True):\n",
    "        if uff_model: \n",
    "            #build grayscale conv layer\n",
    "            grayscale_conv_layer = self.build_conv_grayscale_layer('face')\n",
    "            new_input_tensor = grayscale_conv_layer(input_tensor)\n",
    "            \n",
    "            #initialise base model\n",
    "            img_width, img_height = self.attribute_info['image size']\n",
    "            base_model = ResNet101(input_tensor = Input((img_width, img_height, 1)), include_top=False, weights=None)(new_input_tensor)\n",
    "\n",
    "            # let each layer in model to be trainable\n",
    "            base_model.trainable = True\n",
    "\n",
    "            # x = base_model.output\n",
    "            x = base_model\n",
    "\n",
    "            return x\n",
    "            \n",
    "        else: #Lambda layers are usable in non-uff format\n",
    "            #convert 3-channel input to a grayscale input using Tensorflow Lambda layer\n",
    "            input_tensor = Lambda(lambda c: tf.image.rgb_to_grayscale(c))(input_tensor)\n",
    "\n",
    "            #base model is trained on RGB images (3 channels) --> make grayscale input into 3 channels\n",
    "            input_tensor = Conv2D(3, (3,3), padding ='same')(input_tensor)\n",
    "            \n",
    "            #initialise base model\n",
    "            base_model = Xception(include_top=False, weights='imagenet')\n",
    "\n",
    "            # let each layer in model to be trainable\n",
    "            base_model.trainable = True\n",
    "\n",
    "            #output base model after feeding 3-channel input\n",
    "            x = base_model(input_tensor)\n",
    "            \n",
    "            return x\n",
    "\n",
    "    ################################################\n",
    "    # Assemble Full Model (Combining CNN branches) #\n",
    "    ################################################\n",
    "    def assemble_full_model(self):\n",
    "        ##################\n",
    "        # Initialisation #\n",
    "        ##################\n",
    "        #get img width and height\n",
    "        img_width, img_height = self.attribute_info['image size']\n",
    "        \n",
    "        #obtain attribute class lists\n",
    "        gender_lst = self.attribute_info['attributes']['gender']\n",
    "        age_range_lst = self.attribute_info['attributes']['age_range']\n",
    "        headwear_lst = self.attribute_info['attributes']['headwear']\n",
    "        hair_length_lst = self.attribute_info['attributes']['hair_length']\n",
    "        hair_color_lst = self.attribute_info['attributes']['hair_color']\n",
    "        eyewear_lst = self.attribute_info['attributes']['eyewear']\n",
    "        maskwear_lst = self.attribute_info['attributes']['maskwear']\n",
    "        facial_hair_lst = self.attribute_info['attributes']['facial_hair']\n",
    "        \n",
    "        #initialise input\n",
    "        input_shape = (img_height, img_width, 3)\n",
    "        input_tensor = Input(shape=input_shape)\n",
    "        \n",
    "        #build the CNN branches\n",
    "        color_branch = self.build_color_branch(input_tensor)\n",
    "        print('Color branch built')\n",
    "        fabric_branch = self.build_fabric_branch(input_tensor)\n",
    "        print('Fabric branch built')\n",
    "        face_branch = self.build_face_branch(input_tensor)\n",
    "        print('Face branch built')\n",
    "        \n",
    "        \n",
    "        #################\n",
    "        # Multi-Outputs #\n",
    "        #################\n",
    "\n",
    "        #color branch\n",
    "        hair_color = self.build_fully_connected_layer(color_branch, len(hair_color_lst), 'hair_color')\n",
    "        \n",
    "        #fabric branch \n",
    "        headwear = self.build_fully_connected_layer(fabric_branch, len(headwear_lst), 'headwear')\n",
    "        eyewear = self.build_fully_connected_layer(fabric_branch, len(eyewear_lst), 'eyewear')\n",
    "        maskwear = self.build_fully_connected_layer(fabric_branch, len(maskwear_lst), 'maskwear')\n",
    "        \n",
    "        #face branch\n",
    "        gender = self.build_fully_connected_layer(face_branch, len(gender_lst), 'gender')\n",
    "        age_range = self.build_fully_connected_layer(face_branch, len(age_range_lst), 'age_range')\n",
    "        hair_length = self.build_fully_connected_layer(face_branch, len(hair_length_lst), 'hair_length')\n",
    "        facial_hair = self.build_fully_connected_layer(face_branch, len(facial_hair_lst), 'facial_hair')\n",
    "        \n",
    "        \n",
    "        #######################\n",
    "        # Assemble full model #\n",
    "        #######################\n",
    "\n",
    "        model = Model(inputs = input_tensor, \n",
    "                      outputs = [gender, eyewear, hair_length, facial_hair, headwear, hair_color, maskwear, age_range],\n",
    "                      name ='Face_Attribute')\n",
    "\n",
    "        ####################################\n",
    "        # Verify uniqueness of layer names #\n",
    "        ####################################\n",
    "        #NOTE: duplicated names are preventing trained model to be saved in h5 format\n",
    "        #       REFERENCE: https://github.com/tensorflow/tensorflow/issues/46871\n",
    "        \n",
    "        def verify_unique_layers(model):\n",
    "            weights_names = []\n",
    "            weights_duplicates = []\n",
    "\n",
    "            cnn_layer_names = []\n",
    "            cnn_layer_duplicates = []\n",
    "\n",
    "            #check unqiueness of names of weights of embedding columns\n",
    "            for i, layer in enumerate(model.weights):\n",
    "                if layer.name not in weights_names:\n",
    "                    weights_names.append(layer.name)\n",
    "                else:\n",
    "                    weights_duplicates.append((i, layer.name))\n",
    "            \n",
    "            #check uniqueness of names of CNN layer names\n",
    "            for i, layer in enumerate(model.layers):\n",
    "                if layer.name not in cnn_layer_names:\n",
    "                    cnn_layer_names.append(layer.name)\n",
    "                else:\n",
    "                    cnn_layer_duplicates.append((i, layer.name))\n",
    "            \n",
    "            #change duplicated names\n",
    "            if weights_duplicates:\n",
    "                print(\"Changing duplicated names of weights\")\n",
    "                for i, _ in weights_duplicates:\n",
    "                    model.weights[i]._handle_name = \"EP_\" + str(i) + \"_\"  + model.weights[i].name \n",
    "\n",
    "            if cnn_layer_duplicates:\n",
    "                print(\"Changing duplicated names of CNN layers\")\n",
    "                for i, _ in cnn_layer_duplicates:\n",
    "                    model.layers[i]._handle_name = \"EP_\" + str(i) + \"_\"  + model.layers[i].name\n",
    "            \n",
    "            return model\n",
    "        \n",
    "        model = verify_unique_layers(model)\n",
    "            \n",
    "        print('Full Model Assembled')\n",
    "        return model\n",
    "\n",
    "    ##################\n",
    "    # Model Training #\n",
    "    ##################\n",
    "    def train(self, model, epochs):\n",
    "        #define optimizer\n",
    "        optimizer = Adam(learning_rate = 1e-5)\n",
    "\n",
    "        #compile model\n",
    "        model.compile(optimizer = optimizer, loss = self.loss_dict, loss_weights = self.loss_weights_dict, metrics = self.metrics_dict)\n",
    "\n",
    "        #callbacks\n",
    "        # Model Checkpointer\n",
    "        checkpointer = ModelCheckpoint(filepath = os.path.join(self.attribute_info['weights dir'],\"weights.{epoch:02d}-{val_accuracy:.4f}-{val_loss:.4f}.h5\"), verbose=1, save_best_only=False)\n",
    "        \n",
    "        # Logging with Tensorboard\n",
    "        tensorboard = tf.keras.callbacks.TensorBoard(\n",
    "                                                    log_dir=self.attribute_info['logs dir'],\n",
    "                                                    histogram_freq=0,\n",
    "                                                    write_graph=True,\n",
    "                                                    write_images=True,\n",
    "                                                    update_freq=\"epoch\",\n",
    "                                                    profile_batch=2,\n",
    "                                                    embeddings_freq=0,\n",
    "                                                    embeddings_metadata=None,  \n",
    "                                                    )\n",
    "\n",
    "        # LR on Plateau \n",
    "        reduce_lr_on_plateau = ReduceLROnPlateau(\n",
    "                                                monitor='val_loss', \n",
    "                                                factor=0.1, \n",
    "                                                patience=5, \n",
    "                                                verbose=1,\n",
    "                                                mode='min', \n",
    "                                                min_delta=0.0001, \n",
    "                                                cooldown=0, \n",
    "                                                min_lr=0,\n",
    "                                                )\n",
    "\n",
    "        # Early Stopping\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', min_delta = 0.001, patience = 30, mode='min')\n",
    "\n",
    "        #model training\n",
    "        hist = model.fit(x=self.train_data,\n",
    "                        y=self.train_labels_dict,\n",
    "                        validation_data = (self.test_data, self.test_labels_dict),\n",
    "                        epochs = epochs,\n",
    "                        batch_size = 32,\n",
    "                        verbose = 1,\n",
    "                        callbacks = [checkpointer, tensorboard, reduce_lr_on_plateau]\n",
    "                        )\n",
    "        \n",
    "    ####################\n",
    "    # Model Prediction #\n",
    "    ####################\n",
    "    def predict(self, img_path):\n",
    "\n",
    "        img_size = self.attribute_info['image size']\n",
    "\n",
    "        #preprocess image before prediction\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (img_size[1],img_size[0]), cv2.INTER_LANCZOS4)\n",
    "        img = img/255.\n",
    "        img_array = np.array(img)\n",
    "        img_array = img_array.reshape(-1, img_size[0],img_size[1],3)\n",
    "\n",
    "        #predict image\n",
    "        y_pred = self.model.predict(img_array, verbose =1 )\n",
    "\n",
    "        lst_predict_index = []\n",
    "        for arr in y_pred:\n",
    "            pred_class_index = np.argmax(arr)\n",
    "            lst_predict_index.append(pred_class_index)\n",
    "\n",
    "        i = 0 \n",
    "        str = \"\"\n",
    "        for class_, attr in attribute_info['attributes'].items():\n",
    "            str += class_ + \": \" + attr[lst_predict_index[i]] + \"\\n\"\n",
    "            # lst_predictions.append([class_, attr[lst_predict_index[i]]])\n",
    "            i+=1\n",
    "\n",
    "        print(str)\n",
    "\n",
    "        return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_info = {}\n",
    "\n",
    "#Face Attribute classes: ensure that the attributes are in order\n",
    "attribute_info['attributes'] = {}\n",
    "attribute_info['attributes']['gender'] = ['Female','Male']\n",
    "attribute_info['attributes']['eyewear'] = ['Glasses', 'None', 'Sunglasses', 'Unknown']\n",
    "attribute_info['attributes']['hair_length'] = ['Bald', 'Long', 'Medium', 'Medium', 'Short', 'Unknown']\n",
    "attribute_info['attributes']['facial_hair'] = ['Beard', 'Moustache', 'None', 'Unknown']\n",
    "attribute_info['attributes']['headwear'] = ['Cap', 'Hat', 'None', 'Hat', 'Hijab', 'None', 'Hat']\n",
    "attribute_info['attributes']['hair_color'] = ['Black', 'Blue', 'Brown', 'Grey', 'None', 'Red', 'Unknown', 'White']\n",
    "attribute_info['attributes']['maskwear'] = ['Mask', 'None', 'Unknown']\n",
    "attribute_info['attributes']['age_range'] = ['10s', '20s', '30s', '40s', 'Above 50s', 'Below 10']\n",
    "\n",
    "#loss for each output\n",
    "losses = {\n",
    "    \"gender_output\": \"binary_crossentropy\",\n",
    "    \"eyewear_output\": \"categorical_crossentropy\",\n",
    "    \"hair_length_output\": \"categorical_crossentropy\",\n",
    "    \"facial_hair_output\": \"categorical_crossentropy\",\n",
    "    \"headwear_output\": \"categorical_crossentropy\",\n",
    "    \"hair_color_output\": \"categorical_crossentropy\",\n",
    "    \"maskwear_output\": \"categorical_crossentropy\",\n",
    "    \"age_range_output\": \"categorical_crossentropy\"}\n",
    "\n",
    "attribute_info['loss'] = losses\n",
    "\n",
    "#loss weights for each output\n",
    "loss_weights = {\"gender_output\": 1.0, \n",
    "                \"eyewear_output\": 1.0, \n",
    "                \"hair_length_output\": 1.0, \n",
    "                \"facial_hair_output\": 1.0, \n",
    "                \"headwear_output\": 1.0, \n",
    "                \"hair_color_output\": 1.0, \n",
    "                \"maskwear_output\": 1.0, \n",
    "                \"age_range_output\": 1.0}\n",
    "\n",
    "attribute_info['loss weights'] = loss_weights\n",
    "\n",
    "#model metrics\n",
    "metrics = [\"accuracy\"] # use \"accuracy\" for all outputs\n",
    "attribute_info['metrics'] = metrics\n",
    "\n",
    "#Image size\n",
    "attribute_info['image size'] = (96, 96)\n",
    "\n",
    "#Directories\n",
    "attribute_info['data dir'] = r\"D:\\Daniel\\research\\PA-Head_Dataset\"\n",
    "attribute_info['weights dir'] = r\"E:\\Daniel\\Research\\head_attribute\\weights\\model1\"\n",
    "attribute_info['logs dir'] = r\"E:\\Daniel\\Research\\head_attribute\\logs\\model1\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color branch built\n",
      "Fabric branch built\n",
      "Face branch built\n",
      "Full Model Assembled\n"
     ]
    }
   ],
   "source": [
    "# Assemble full multi-ouput model\n",
    "multioutput = MultiOutputModel(attribute_info, items)\n",
    "model = multioutput.assemble_full_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Daniel\\research\\scripts\\folder\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "epochs = 100\n",
    "# multioutput.train(model, epochs)\n",
    "p = os.getcwd() + '\\\\folder'\n",
    "i = f'{p}'\n",
    "r = r'{}'.format(i)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-29 14:36:58.141346: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################################################\n",
    "# Trial and error to convert RGB image to grayscale image using Conv2D layer #\n",
    "##############################################################################\n",
    "\n",
    "input = r\"/Users/danielng/Documents/xrvision/PSA/data/Orange Vests/Orange Vests Frames/74sim.jpg\"\n",
    "img1 = cv2.imread(input)\n",
    "img = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "gray_img = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "input_tensor = np.array(img, dtype='float32')\n",
    "\n",
    "input_tensor = np.expand_dims(input_tensor, axis=0)\n",
    "# weights = np.array([0.299, 0.587, 0.114])\n",
    "weights = np.array([[[[ 0.299],\n",
    "         [0.587 ],\n",
    "         [0.114]]]], dtype='float32')\n",
    "\n",
    "# x = Conv2D(1, (1,1), padding = 'same')(input_tensor)\n",
    "# x = Conv2D(1, (1,1), padding='same', activation = 'relu')\n",
    "# x = Conv2D(1, (1,1), padding = 'same', activation = None, bias_initializer='zeros', kernel_initializer=None, trainable = False)\n",
    "x = Conv2D(1, kernel_size=(1, 1),kernel_initializer=tf.keras.initializers.zeros(), activation=\"relu\",use_bias=True,name='conv1_convert_grayscale')\n",
    "x = Conv2D(1, kernel_size=(1, 1),kernel_initializer=tf.keras.initializers.Constant(value=weights), activation=None,use_bias=True,name='conv1_convert_grayscale')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(x)\n",
    "# model.layers[0].trainable = False\n",
    "y = model(input_tensor)\n",
    "model.get_weights()\n",
    "path = r'/Users/danielng/Documents/xrvision/Research/Face Attribute/data/img.jpg'\n",
    "\n",
    "y = y[0]\n",
    "y = np.array(y)\n",
    "cv2.imwrite(path, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 5.5699\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Model sucessfully loaded\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# Model Prediction #\n",
    "####################\n",
    "\n",
    "model_path = r\"E:\\Daniel\\Research\\head_attribute\\best_weights\\weights.26-5.5550.h5\"\n",
    "multioutput = MultiOutputModel(attribute_info, processed_data = False, model_path= model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 78ms/step\n",
      "gender: Male\n",
      "eyewear: None\n",
      "hair_length: Short\n",
      "facial_hair: None\n",
      "headwear: None\n",
      "hair_color: Black\n",
      "maskwear: None\n",
      "age_range: 20s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "img_path = r\"E:\\Daniel\\Research\\head_attribute\\test_data\\20191030_121201_thumb0179_0.jpg\"\n",
    "\n",
    "multioutput.predict(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 5.5699\n"
     ]
    }
   ],
   "source": [
    "path = r\"E:\\Daniel\\Research\\head_attribute\\weights\\model1\"\n",
    "\n",
    "best = 6\n",
    "best_epoch =0\n",
    "for w_path in glob.glob(path + '\\*'):\n",
    "    epoch = w_path.split('-')[0].split('weights.')[-1]\n",
    "    val_loss = float(w_path.split('-')[-1].split('.h5')[0])\n",
    "    if val_loss<best:\n",
    "        best = val_loss\n",
    "        best_epoch = epoch\n",
    "\n",
    "print(best_epoch, best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8b782a351391c2b504ef617b3579652ee72b916bcd226c7dd794f4652190563"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('tensorflow2': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
