{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "import imutils\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageOps, ImageEnhance, ImageFilter\n",
    "\n",
    "\n",
    "class ObjectAugmentation():\n",
    "\n",
    "    #############################\n",
    "    # Bounding Box Augmentation #\n",
    "    #############################\n",
    "\n",
    "    # returns width, height, top left and bottom right coordinates of object contour's bounding box\n",
    "    def bbox_info(self, contour, random_x_coord, random_y_coord):\n",
    "        c = contour\n",
    "\n",
    "        extreme_Left = tuple(c[c[:, :, 0].argmin()][0])\n",
    "        extreme_Right = tuple(c[c[:, :, 0].argmax()][0])\n",
    "        extreme_Top = tuple(c[c[:, :, 1].argmin()][0])\n",
    "        extreme_Bottom = tuple(c[c[:, :, 1].argmax()][0])\n",
    "\n",
    "        # coordinates wrt to contour\n",
    "        x_start = extreme_Left[0]\n",
    "        y_start = extreme_Top[1]\n",
    "        x_end = extreme_Right[0]\n",
    "        y_end = extreme_Bottom[1]\n",
    "\n",
    "        # width and height of bounding box\n",
    "        bbox_width = x_end - x_start\n",
    "        bbox_height = y_end - y_start\n",
    "\n",
    "        #coordinates of bbox wrt to background image\n",
    "        x_start = random_x_coord + x_start\n",
    "        y_start = random_y_coord + y_start\n",
    "        x_end = x_start + bbox_width\n",
    "        y_end = y_start + bbox_height\n",
    "\n",
    "        return(x_start, y_start, x_end, y_end, bbox_width, bbox_height)\n",
    "\n",
    "\n",
    "    # get xml path for labelled person\n",
    "    def find_xml(self, img_fname):\n",
    "        if '.jpg' in img_fname:\n",
    "            fname = img_fname.split('.jpg')[0]\n",
    "        elif '.png' in img_fname:\n",
    "            fname = img_fname.split('.png')[0]\n",
    "        xml_path = fname + '.xml'\n",
    "        return xml_path\n",
    "\n",
    "    \n",
    "    # get coordinates of bbox in xml file\n",
    "    def extract_coords(self, xml_path, obj_name):\n",
    "        x_value = 1\n",
    "        y_value = 1\n",
    "        coords = []\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        for object in root.findall('object'):\n",
    "            name = object.find('name').text\n",
    "            if(name == obj_name):\n",
    "                bbox = object.find('bndbox')\n",
    "                # for cords in bbox:\n",
    "                xmin = int(int((bbox.find('xmin').text))/x_value) #1.02 - 1.03 for side views\n",
    "                ymin = int(int((bbox.find('ymin').text))/y_value)\n",
    "                xmax = int(int((bbox.find('xmax').text))*x_value)\n",
    "                ymax = int(int((bbox.find('ymax').text))*y_value)\n",
    "                coords.append([xmin,ymin,xmax,ymax])\n",
    "            \n",
    "        return coords\n",
    "\n",
    "    \n",
    "    # returns normalized coordinates of bbox\n",
    "    def normalize_coords(self, bbox_info, frame_width, frame_height):\n",
    "        # get bbox information\n",
    "        obj_x_start, obj_y_start, obj_x_end, obj_y_end, obj_width, obj_height = bbox_info\n",
    "         \n",
    "        # center points of object\n",
    "        center_x = (obj_x_start + obj_x_end)/2\n",
    "        center_y = (obj_y_start + obj_y_end)/2\n",
    "\n",
    "        # normalize coordinates\n",
    "        normalized_center_x = center_x/frame_width\n",
    "        normalized_center_y = center_y/frame_height\n",
    "\n",
    "        normalized_obj_width = obj_width/frame_width\n",
    "        normalized_obj_height = obj_height/frame_height\n",
    "\n",
    "        return [normalized_center_x, normalized_center_y, normalized_obj_width, normalized_obj_height]\n",
    "    \n",
    "    \n",
    "    # creates rotation matrix to rotate bbox\n",
    "    def rotation_matrix(self, img_center_point, augmented_img_dim, angle):\n",
    "        #get new dimensions of augmented image\n",
    "        new_img_width, new_img_height = augmented_img_dim\n",
    "\n",
    "        #get center point coords\n",
    "        img_center_x, img_center_y = img_center_point\n",
    "\n",
    "        #get rotation matrix\n",
    "        matrix = cv2.getRotationMatrix2D((img_center_x, img_center_y), angle, 1)\n",
    "\n",
    "        #adjust rotation matrix to take into account translation\n",
    "        matrix[0,2] += (new_img_width/2) - img_center_x\n",
    "        matrix[1,2] += (new_img_height/2) - img_center_y\n",
    "\n",
    "        return matrix\n",
    "    \n",
    "    # returns corner points of bbox: array of shape '1 x 8'\n",
    "    def get_corner_points(self, bbox_info):\n",
    "        #get bbox information\n",
    "        xmin, ymin, xmax, ymax, _, _ = bbox_info\n",
    "        \n",
    "        #top left corner\n",
    "        x1, y1 = xmin, ymin\n",
    "\n",
    "        #top right corner\n",
    "        x2, y2 = xmax, ymin\n",
    "\n",
    "        #bottom left corner\n",
    "        x3, y3 = xmin, ymax\n",
    "        \n",
    "        #bottom right corner\n",
    "        x4, y4 = xmax, ymax\n",
    "        corner_points = np.hstack((x1,y1,x2,y2,x3,y3,x4,y4))\n",
    "        \n",
    "        return corner_points\n",
    "        \n",
    "    # returns new corner points of bbox after augmentation: rotation will cause bbox to be at an angle so we will find the tightest upright box to enclose object\n",
    "    def get_enclosed_box(self, corner_points):\n",
    "        #get x and y coordinates separately\n",
    "        x_ = corner_points[:,[0]]\n",
    "        y_ = corner_points[:,[1]]\n",
    "        \n",
    "        #get the coordinates of upright bbox\n",
    "        xmin = np.min(x_)\n",
    "        ymin = np.min(y_)\n",
    "        xmax = np.max(x_)\n",
    "        ymax = np.max(y_)\n",
    "        \n",
    "        enclosed_box = np.hstack((xmin, ymin, xmax, ymax))\n",
    "        \n",
    "        return enclosed_box\n",
    "        \n",
    "\n",
    "    # returns new bbox coordinates given rotation angle\n",
    "    # NOTE: reference: https://blog.paperspace.com/data-augmentation-for-object-detection-rotation-and-shearing/\n",
    "    def rotate_bbox(self, bbox_info, augmentation):\n",
    "        #get augmentation information\n",
    "        augmented_img, augment = augmentation\n",
    "\n",
    "        #get new width and height of augmented image\n",
    "        new_img_width, new_img_height = augmented_img.size\n",
    "\n",
    "        #get initial bbox information\n",
    "        xmin, ymin, xmax, ymax, old_img_width, old_img_height = bbox_info\n",
    "\n",
    "        #get center point of initial image: rotation is about the center point of entire image\n",
    "        img_center_x, img_center_y = old_img_width//2, old_img_height//2\n",
    "\n",
    "        #if augmentation is flipping object horizontally\n",
    "        if augment == 'mirrored':\n",
    "            new_xmin = old_img_width - bbox_info[2]\n",
    "            new_xmax = old_img_width - bbox_info[0]\n",
    "            bbox_info[0] = new_xmin\n",
    "            bbox_info[2] = new_xmax\n",
    "            return bbox_info\n",
    "        \n",
    "        elif type(augment) == int:\n",
    "            angle = augment\n",
    "        \n",
    "        #create rotation matrix\n",
    "        rot_matrix = self.rotation_matrix((img_center_x, img_center_y), augmented_img.size, angle)\n",
    "\n",
    "        #get corner points of bbox in a 1x8 vector\n",
    "        corner_points = self.get_corner_points(bbox_info)\n",
    "        corner_points = corner_points.reshape(-1,2)\n",
    "        corner_points = np.hstack((corner_points, np.ones((corner_points.shape[0],1))))\n",
    "\n",
    "        #get new coordinates of bbox after rotation\n",
    "        new_corner_points = np.dot(rot_matrix, corner_points.T).T\n",
    "\n",
    "        #rotate bbox and get new bbox coordinates\n",
    "        new_enclosed_bbox = self.get_enclosed_box(new_corner_points)\n",
    "        \n",
    "        #update bbox information\n",
    "        new_bbox_info = list(new_enclosed_bbox)\n",
    "        new_bbox_info.extend([new_img_width, new_img_height])\n",
    "        \n",
    "        return new_bbox_info\n",
    "\n",
    "\n",
    "\n",
    "    # updates head bbox for each augmentation\n",
    "    def update_head_bbox_info(self, initial_img_size, bg_size, head_bbox_file, random_coords, augmentations):\n",
    "        #get generated random_coords\n",
    "        random_x_coord, random_y_coord = random_coords\n",
    "\n",
    "        #get background frame width and height\n",
    "        frame_width, frame_height = bg_size\n",
    "\n",
    "        #get coordinates of bbox from XML file\n",
    "        xml_path = self.find_xml(head_bbox_file)\n",
    "        coords = self.extract_coords(xml_path, 'head')[0]\n",
    "\n",
    "        #rotate head bbox and update latest bbox information\n",
    "        coords.extend(initial_img_size)\n",
    "        new_bbox_info = coords\n",
    "\n",
    "        for augmentation in augmentations:\n",
    "            new_bbox_info = self.rotate_bbox(new_bbox_info, augmentation)\n",
    "        \n",
    "        #coordinates of bbox wrt background image\n",
    "        bbox_width = abs(new_bbox_info[2] - new_bbox_info[0])\n",
    "        bbox_height = abs(new_bbox_info[3] - new_bbox_info[1])\n",
    "\n",
    "        new_bbox_info[0] = random_x_coord + new_bbox_info[0]     #x_start = random_x + xmin\n",
    "        new_bbox_info[1] = random_y_coord + new_bbox_info[1]     #y_start = random_y + ymin\n",
    "        new_bbox_info[2] = new_bbox_info[0] + bbox_width   #x_end = x_start + bbox_width\n",
    "        new_bbox_info[3] = new_bbox_info[1] + bbox_height  #y_end = y_start + bbox_height\n",
    "        \n",
    "        new_bbox_info[4], new_bbox_info[5] = bbox_width, bbox_height\n",
    "        \n",
    "        #normalize head bbox coords\n",
    "        norm_head_bbox_info = self.normalize_coords(new_bbox_info, frame_width, frame_height)\n",
    "\n",
    "        norm_head_bbox_info.insert(0, 0) #head class is index 0\n",
    "        return norm_head_bbox_info\n",
    "\n",
    "\n",
    "    # returns YOLO information given object mask for augmentation\n",
    "    def get_yolo_information(self, obj_mask, random_x_coord, random_y_coord, frame_width, frame_height):\n",
    "        # get contour of object\n",
    "        height, width = obj_mask.shape[:2]\n",
    "        obj_mask = cv2.resize(obj_mask, (height, width)) #resize mask to get correct bbox size\n",
    "        contour = self.object_contour(obj_mask)\n",
    "\n",
    "        # get dimensions and coordinates of object: obj_x_start, obj_y_start, obj_x_end, obj_y_end, obj_width, obj_height\n",
    "        bbox_info = self.bbox_info(contour, random_x_coord, random_y_coord)\n",
    "        \n",
    "        # get normalized bbox info\n",
    "        norm_bbox_info = self.normalize_coords(bbox_info, frame_width, frame_height)\n",
    "\n",
    "        return norm_bbox_info\n",
    "\n",
    "\n",
    "\n",
    "    # check validity of coordinates: if center point is out of image, disregard entire yolo information \n",
    "    def verify_yolo_information(self, yolo_info):\n",
    "        label, center_x, center_y, bbox_width, bbox_height = yolo_info\n",
    "        if type(label) != int:\n",
    "            return False\n",
    "        if center_x>1 or center_x<0:\n",
    "            return False\n",
    "        if center_y>1 or center_y<0:\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "\n",
    "    #########################\n",
    "    # Tel-Aviv Augmentation #\n",
    "    #########################\n",
    "\n",
    "    # initialize smallest and largest object sizes and boundary coordinates given a background image\n",
    "    def initialize_sizes_and_coordinates(self, bg_path, scale=1, TAV_cam_view=None, same_environment=None):\n",
    "        #NOTE: for same_environment objects are scaled according to Tel-Aviv frame dimension: 1920 x 1080 (height, width)\n",
    "        #      Thus, any other dimensions will be scaled to TAV frame dimension\n",
    "        #NOTE: np.array([width, height])\n",
    "\n",
    "        if not same_environment:\n",
    "            if not TAV_cam_view: #i.e generic bg images\n",
    "                # get width and height of background image\n",
    "                bg_width, bg_height = Image.open(bg_path).size\n",
    "\n",
    "                # get ratios of width and height\n",
    "                width_ratio, height_ratio = (bg_width/1080), (bg_height/1920)\n",
    "                nearest_obj = np.array([60*width_ratio , 150*height_ratio])*scale #closest to cam\n",
    "                furthest_obj = np.array([20*width_ratio, 50*height_ratio])*scale #furthest to cam     \n",
    "\n",
    "                boundary_x, boundary_y = 0, 0\n",
    "            \n",
    "            elif 'cam1' in TAV_cam_view: #nearest: leftside, furthest: rightside\n",
    "                nearest_obj = np.array([150 , 165])*scale #leftside\n",
    "                furthest_obj = np.array([120 , 135])*scale #rightside\n",
    "\n",
    "                boundary_x, boundary_y = 0, 400\n",
    "\n",
    "            elif 'cam2' in TAV_cam_view:\n",
    "                nearest_obj = np.array([120 , 135])*scale #leftside\n",
    "                furthest_obj = np.array([80 , 95])*scale #rightside\n",
    "\n",
    "                boundary_x, boundary_y = 0, 600\n",
    "\n",
    "            elif 'cam3' in TAV_cam_view or 'cam4' in TAV_cam_view:\n",
    "                nearest_obj = np.array([150 , 200])*scale #bottom\n",
    "                furthest_obj = np.array([30, 60])*scale #top\n",
    "            \n",
    "                if 'cam3' in TAV_cam_view:\n",
    "                    boundary_x, boundary_y = 900, 850\n",
    "                else:\n",
    "\n",
    "                    boundary_x, boundary_y = 950, 850\n",
    "\n",
    "            return (nearest_obj, furthest_obj, boundary_x, boundary_y)\n",
    "\n",
    "        else:\n",
    "            # all same_environment objects are scaled to TAV already\n",
    "            nearest_obj = None\n",
    "            furthest_obj =  None \n",
    "            if not TAV_cam_view:\n",
    "                boundary_x, boundary_y = 200, 200\n",
    "            elif 'cam1' in TAV_cam_view:\n",
    "                boundary_x, boundary_y = 30, 400\n",
    "            elif 'cam2' in TAV_cam_view:\n",
    "                boundary_x, boundary_y = 30, 400\n",
    "            elif 'cam3' in TAV_cam_view:\n",
    "                boundary_x, boundary_y = 1100, 650\n",
    "            elif 'cam4' in TAV_cam_view:\n",
    "                boundary_x, boundary_y = 750, 850\n",
    "            \n",
    "            return (nearest_obj, furthest_obj, boundary_x, boundary_y)\n",
    "\n",
    "    # returns random coordinates\n",
    "    def random_coords(self, frame_width, frame_height, boundary_x, boundary_y, TAV_cam_view=None):\n",
    "        if not TAV_cam_view:\n",
    "            x, y = random.randint(boundary_x, frame_width-200), random.randint(boundary_y, frame_height-200)\n",
    "        elif 'cam1' in TAV_cam_view:\n",
    "            x, y = random.randint(boundary_x, frame_width-400), random.randint(boundary_y, 900)\n",
    "        elif 'cam2' in TAV_cam_view:\n",
    "            x, y = random.randint(boundary_x, 1500), random.randint(boundary_y, 850)\n",
    "        \n",
    "        elif 'cam3' in TAV_cam_view:\n",
    "            x, y = random.randint(boundary_x, frame_width-200), random.randint(100, boundary_y)\n",
    "        \n",
    "        elif 'cam4' in TAV_cam_view:\n",
    "            x, y = random.randint(1, boundary_x), random.randint(100, boundary_y)\n",
    "        return (x,y)\n",
    "\n",
    "\n",
    "\n",
    "    # returns desired size of object given random coords\n",
    "    def desired_size(self, random_coords, nearest_obj, furthest_obj, frame_width, frame_height, TAV_cam_view=None):\n",
    "        # get x-y coordinates\n",
    "        x,y = random_coords\n",
    "        if not TAV_cam_view:\n",
    "            size = ((y/frame_height) * (nearest_obj- furthest_obj)) + furthest_obj\n",
    "            size = tuple(map(int,size))\n",
    "        elif 'cam1' in TAV_cam_view or 'cam2' in TAV_cam_view: #sideview\n",
    "            size = ((x/frame_width) * (nearest_obj- furthest_obj)) + furthest_obj\n",
    "            size = tuple(map(int,size))\n",
    "        elif 'cam3' in TAV_cam_view or 'cam4' in TAV_cam_view: #front-back view\n",
    "            size = ((y/frame_height) * (nearest_obj- furthest_obj)) + furthest_obj\n",
    "            size = tuple(map(int,size))\n",
    "        return size\n",
    "\n",
    "\n",
    "    # returns new resized image based on desired width: for cam1 and cam2\n",
    "    def image_resize_by_width(self, img, desired_width):\n",
    "        orig_width, orig_height = img.size\n",
    "        ratio = desired_width/orig_width\n",
    "        \n",
    "        new_size = (desired_width, int(orig_height*ratio))\n",
    "\n",
    "        new_img = img.resize(new_size)\n",
    "        return new_img\n",
    "\n",
    "\n",
    "\n",
    "    # returns new resized image based on desired height: for cam3 and cam4\n",
    "    def image_resize_by_height(self, img, desired_height):\n",
    "        orig_width, orig_height = img.size\n",
    "        ratio = desired_height/orig_height\n",
    "\n",
    "        new_size = (int(orig_width*ratio), desired_height)\n",
    "\n",
    "        new_img = img.resize(new_size)\n",
    "        return new_img\n",
    "\n",
    "\n",
    "\n",
    "    # returns resized image based on cam_view\n",
    "    def image_resize(self, img, desired_size, TAV_cam_view=None):\n",
    "        if not TAV_cam_view:\n",
    "            return self.image_resize_by_height(img, desired_size[1])\n",
    "        elif 'cam1' in TAV_cam_view or 'cam2' in TAV_cam_view:\n",
    "            return self.image_resize_by_width(img, desired_size[0])\n",
    "        \n",
    "        elif 'cam3' in TAV_cam_view or 'cam4' in TAV_cam_view:\n",
    "            return self.image_resize_by_height(img, desired_size[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #################################\n",
    "    # Augmentation Helper Functions #\n",
    "    #################################\n",
    "\n",
    "    # ensures image format is PNG when running opencv operations\n",
    "    def png_format(self, img, pixel_threshold):\n",
    "\n",
    "        if type(img) is str: #if image path\n",
    "            filename = img.split('\\\\')[-1]\n",
    "            if 'png' in filename: #if image is PNG\n",
    "                img = cv2.imread(img, -1)  #imread_unchanged: read image and include alpha channel\n",
    "                return img\n",
    "\n",
    "            else:\n",
    "                jpg_or = cv2.imread(img)\n",
    "\n",
    "\n",
    "        else: # if image object (PIL format)\n",
    "            img_array = np.array(img)\n",
    "\n",
    "            if img_array.shape[2] == 4: # if image object is PNG\n",
    "                return img_array\n",
    "            \n",
    "            else: #image object is RGB: 3 channels\n",
    "                jpg_or = img_array\n",
    "        \n",
    "        z = np.ones(jpg_or.shape[:-1] + (1,), dtype=jpg_or.dtype)\n",
    "        z = z*255\n",
    "        jpg = np.concatenate((jpg_or, z), axis=-1)\n",
    "\n",
    "\n",
    "        white_pixels = np.where(\n",
    "            (jpg[:, :, 0] >= pixel_threshold) & \n",
    "            (jpg[:, :, 1] >= pixel_threshold) & \n",
    "            (jpg[:, :, 2] >= pixel_threshold))\n",
    "\n",
    "        for x,y in zip(white_pixels[0],white_pixels[1]):\n",
    "            jpg[x,y,3] = 0\n",
    "\n",
    "        png = cv2.cvtColor(jpg, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "        return png\n",
    "\n",
    "\n",
    "\n",
    "    # condition for overlapping object with other objects\n",
    "    def overlap_coords(self, non_overlap_size_lst, threshold = 1):\n",
    "        #NOTE: threshold value determines how much overlapping is allowed (1: 0% overlap allowed, 0: 100% overlap allowed)\n",
    "\n",
    "        if len(non_overlap_size_lst) == 1:\n",
    "            return False\n",
    "\n",
    "        else:\n",
    "            # get current size and coordinates\n",
    "            current_size, current_coords = non_overlap_size_lst[-1]\n",
    "\n",
    "            # desired width and desired height of current size\n",
    "            current_width, current_height = current_size\n",
    "\n",
    "            # get current coordinates\n",
    "            current_x, current_y = current_coords #current random coordinates\n",
    "\n",
    "            # get width and height thresholds\n",
    "            width_threshold, height_threshold = current_width*threshold, current_height*threshold\n",
    "\n",
    "            # check that current size satisfy overlapping condition\n",
    "            for indx in range(len(non_overlap_size_lst)-1):\n",
    "                # get past coordinates\n",
    "                past_coords = non_overlap_size_lst[indx][1]\n",
    "                past_x, past_y = past_coords\n",
    "\n",
    "                # get difference in width and height\n",
    "                width_diff, height_diff = abs(current_x - past_x), abs(current_y - past_y)\n",
    "\n",
    "                #if difference is smaller than threshold: too much overlapping\n",
    "                if width_diff < width_threshold or height_diff < height_threshold:\n",
    "                    non_overlap_size_lst.pop(-1) #remove current coordinates\n",
    "                    return True\n",
    "            \n",
    "            return False\n",
    "\n",
    "\n",
    "    # returns random coordinates and desired size of object given those coordinates\n",
    "    def get_random_coords_and_size(self, obj_path, non_overlap_size_lst, frame_width, frame_height, nearest_obj, furthest_obj, boundary_x, boundary_y, TAV_cam_view=None, same_environment = False):\n",
    "        # get image in PIL format\n",
    "        orig_img = Image.open(obj_path)\n",
    "\n",
    "        # initialize random coordinates\n",
    "        random_coordinates = self.random_coords(frame_width, frame_height, boundary_x, boundary_y, TAV_cam_view)\n",
    "\n",
    "        # initialize desired size given random coordinates\n",
    "        if not same_environment:\n",
    "\n",
    "            size = self.desired_size(random_coordinates, nearest_obj, furthest_obj, frame_width, frame_height, TAV_cam_view)\n",
    "        \n",
    "            # resize image based on desired size\n",
    "            img = self.image_resize(orig_img, size, TAV_cam_view)\n",
    "            size = img.size\n",
    "\n",
    "        else:\n",
    "            size = orig_img.size\n",
    "\n",
    "        # keep track of non-overlapping objects\n",
    "        non_overlap_size_lst.append((size, random_coordinates))\n",
    "\n",
    "        # condition to ensure objects do not overlap too much\n",
    "        counter = 100000\n",
    "        while self.overlap_coords(non_overlap_size_lst) and counter!=0:\n",
    "            # re-initialize coordinates\n",
    "            random_coordinates = self.random_coords(frame_width, frame_height, boundary_x, boundary_y, TAV_cam_view)\n",
    "\n",
    "            #re-initialize desired size\n",
    "            if not same_environment:\n",
    "                size = self.desired_size(random_coordinates, nearest_obj, furthest_obj, frame_width, frame_height, TAV_cam_view)\n",
    "                \n",
    "                # resize image based on re-initialized desired size\n",
    "                img = self.image_resize(orig_img, size, TAV_cam_view)\n",
    "                size = img.size\n",
    "\n",
    "            counter-=1\n",
    "            if counter==0:\n",
    "                print('unable to find a non-overlapping point')\n",
    "\n",
    "        return random_coordinates, size, non_overlap_size_lst\n",
    "\n",
    "\n",
    "\n",
    "    # returns randomly augmented object image: version 1 -> non-living objects\n",
    "    def random_augmentv1(self, image):\n",
    "        yes_or_no = ['Yes', 'No']\n",
    "\n",
    "        if random.choice(yes_or_no) == 'Yes':\n",
    "            image = ImageOps.mirror(image) #flip horizontally\n",
    "\n",
    "        if random.choice(yes_or_no) == 'Yes':\n",
    "            if np.array(image).shape[2] == 4: #if image is PNG, i.e 4 channels\n",
    "                brightness_factor = random.uniform(0.5,1.5) #adjust brightness\n",
    "                image = ImageEnhance.Brightness(image).enhance(brightness_factor) \n",
    "\n",
    "        if random.choice(yes_or_no) == 'Yes':\n",
    "            angle = random.randint(1, 20) #rotate image counter-clockwise\n",
    "            if np.array(image).shape[2] == 3: #if image is JPEG, i.e 3 channels\n",
    "                image = image.rotate(angle, Image.NEAREST, fillcolor='white', expand=True)\n",
    "            elif np.array(image).shape[2] == 4: #if image is PNG, i.e 4 channels\n",
    "                image = image.rotate(angle, Image.NEAREST, expand=True)\n",
    "\n",
    "        # if random.choice(yes_or_no) == 'Yes':\n",
    "        #     if np.array(image).shape[2] == 4: #if image is PNG, i.e 4 channels\n",
    "        #         contrast_factor = random.uniform(0.5, 1.5) #adjust contrast\n",
    "        #         image = ImageEnhance.Contrast(image).enhance(contrast_factor)\n",
    "\n",
    "        if random.choice(yes_or_no) == 'Yes':\n",
    "            image = image.filter(ImageFilter.BoxBlur(1)) #add box blurring, radius size = 1\n",
    "        \n",
    "        # if random.choice(yes_or_no) == 'Yes':\n",
    "        #     factor = random.randint(-5,5)\n",
    "        #     image = ImageEnhance.Color(image).enhance(factor) #adjust saturation\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "    # returns randomly augmented object image: version 2 -> living objects\n",
    "    def random_augmentv2(self, image, bg_image, random_coords, head_bbox_file=None, fallen_person = False):\n",
    "        yes_or_no = ['Yes', 'No']\n",
    "        augmentations = []\n",
    "\n",
    "        # initial image and background sizes\n",
    "        initial_img_size = image.size\n",
    "        bg_size = bg_image.size\n",
    "\n",
    "        if fallen_person: #rotate upright object on its side to mimick fallen object\n",
    "            if np.array(image).shape[2] == 3:\n",
    "                image = image.rotate(90, Image.NEAREST, fillcolor = 'white', expand= True)\n",
    "            elif np.array(image).shape[2] == 4: #if image is PNG, i.e 4 channels\n",
    "                image = image.rotate(90, Image.NEAREST, expand =True)\n",
    "            augmentations.append((image, 90))\n",
    "\n",
    "        if random.choice(yes_or_no) == 'Yes':\n",
    "            image = ImageOps.mirror(image) #flip horizontally\n",
    "            augmentations.append((image,'mirrored'))\n",
    "\n",
    "        if random.choice(yes_or_no) == 'Yes':\n",
    "            if np.array(image).shape[2] == 3:\n",
    "                angle = random.randint(-20, 20)\n",
    "                image = image.rotate(angle, Image.NEAREST, fillcolor = 'white', expand = True) #rotate person at a slight angle\n",
    "                augmentations.append((image,angle))\n",
    "            elif np.array(image).shape[2] == 4: #if image is PNG, i.e 4 channels\n",
    "                image = image.rotate(90, Image.NEAREST, expand =True)\n",
    "            augmentations.append((image, angle))\n",
    "            \n",
    "        # if random.choice(yes_or_no) == 'Yes':\n",
    "        #     if np.array(image).shape[2] == 4: #if image is PNG, i.e 4 channels\n",
    "        #         contrast_factor = random.uniform(0.5, 1.5) #adjust contrast\n",
    "        #         image = ImageEnhance.Contrast(image).enhance(contrast_factor)\n",
    "\n",
    "        if head_bbox_file:\n",
    "            head_bbox_info = self.update_head_bbox_info(initial_img_size, bg_size, head_bbox_file, random_coords, augmentations)\n",
    "            return image, head_bbox_info\n",
    "\n",
    "        return image\n",
    "\n",
    "    # returns roi of background given object and random coords\n",
    "    def bg_roi_img(self, resized_obj_img, bg_img, random_x_coord, random_y_coord):\n",
    "\n",
    "        # convert PIL format to array for opencv operations\n",
    "        bg = np.array(bg_img)\n",
    "        \n",
    "        # dimesions of resized object image\n",
    "        width, height = resized_obj_img.size\n",
    "\n",
    "        # get desired coordinates of ROI in background image to place object\n",
    "        desired_x_start = random_x_coord\n",
    "        desired_y_start = random_y_coord\n",
    "        desired_x_end = desired_x_start + width\n",
    "        desired_y_end = desired_y_start + height\n",
    "        \n",
    "        # crop background image based on ROI coordinates\n",
    "        roi = bg[desired_y_start:desired_y_end, desired_x_start:desired_x_end]\n",
    "    \n",
    "        #change width, height to height, width\n",
    "        roi = cv2.resize(roi, (height, width))\n",
    "\n",
    "        return roi #opencv format\n",
    "\n",
    "\n",
    "\n",
    "    # returns contour of object in image\n",
    "    def object_contour(self, obj_mask):\n",
    "        # find all contours from object mask\n",
    "        contours = cv2.findContours(obj_mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = imutils.grab_contours(contours)\n",
    "\n",
    "        # get largest contour: assuming it is the object\n",
    "        contour = max(contours, key = cv2.contourArea)\n",
    "        return contour\n",
    "\n",
    "\n",
    "    \n",
    "    # returns object mask and inverted mask\n",
    "    def obj_mask_and_inverted_mask(self, resized_img):\n",
    "        # dimesions of resized object given random coords\n",
    "        width, height = resized_img.size\n",
    "\n",
    "        # read image using opencv to perform bitwise operations\n",
    "        object = self.png_format(resized_img, 240)\n",
    "        object = cv2.resize(object, (height, width))\n",
    "\n",
    "        # create object mask and inverted mask\n",
    "        obj_mask = object[:,:,3]\n",
    "        obj_mask_inverted = cv2.bitwise_not(obj_mask) #returns one’s complement of the number\n",
    "\n",
    "\n",
    "        return (obj_mask, obj_mask_inverted) #opencv format\n",
    "\n",
    "\n",
    "\n",
    "    # returns object background and foreground images given object mask and inverted mask\n",
    "    def object_foreground_and_background(self, obj_mask, obj_mask_inverted, roi, resized_object_img):\n",
    "        # dimesions of resized object given random coords\n",
    "        width, height = resized_object_img.size\n",
    "\n",
    "        # read image and convert to BGR for opencv operations\n",
    "        object = self.png_format(resized_object_img, 240)\n",
    "        object = cv2.resize(object, (height, width))\n",
    "        object = cv2.cvtColor(object, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # get bg and fg images\n",
    "        bg = cv2.bitwise_and(roi, roi, mask = obj_mask_inverted)\n",
    "        fg = cv2.bitwise_and(object, object, mask = obj_mask)\n",
    "\n",
    "        # convert foreground to RGB\n",
    "        fg = cv2.cvtColor(fg, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        return(bg, fg) #opencv format\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # returns object img with selected background\n",
    "    def img_with_mask(self, resized_object_img, bg_img, random_coordinates, frame_width, frame_height, TAV_cam_view = None):\n",
    "        # get x-y coordinates\n",
    "        random_x_coord, random_y_coord = random_coordinates\n",
    "\n",
    "        # get ROI of background image\n",
    "        bg_roi = self.bg_roi_img(resized_object_img, bg_img, random_x_coord, random_y_coord)\n",
    "        \n",
    "        # get object mask and inverted mask\n",
    "        obj_mask, obj_mask_inverted = self.obj_mask_and_inverted_mask(resized_object_img)\n",
    "        \n",
    "        # get YOLO information\n",
    "        yolo_info = self.get_yolo_information(obj_mask, random_x_coord, random_y_coord, frame_width, frame_height)\n",
    "\n",
    "        # get object background and foreground images\n",
    "        obj_bg, obj_fg = self.object_foreground_and_background(obj_mask, obj_mask_inverted, bg_roi, resized_object_img)\n",
    "\n",
    "        # combine obj bg and fg images together\n",
    "        img_with_mask = cv2.add(obj_bg, obj_fg)\n",
    "        img_with_mask = Image.fromarray(np.uint8(img_with_mask))\n",
    "        img_with_mask = img_with_mask.resize(resized_object_img.size) #opencv height/width to PIL height/width\n",
    "\n",
    "        return (img_with_mask, yolo_info)\n",
    "\n",
    "\n",
    "\n",
    "    # overlays object on background\n",
    "    def overlay_img_on_bg(self, img_with_mask, bg_img, random_coords):\n",
    "        bg_img.paste(img_with_mask, random_coords)\n",
    "        return bg_img\n",
    "\n",
    "\n",
    "    # converts RGBA PNG to RGB\n",
    "    def format_rgb(self, image):\n",
    "        background = Image.new('RGB', image.size, (255, 255, 255))\n",
    "        background.paste(image, mask = image.split()[3])\n",
    "        return background\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    ##################################\n",
    "    # Preprocessing Helper Functions #\n",
    "    ##################################\n",
    "\n",
    "    # creates text file for each background image\n",
    "    def create_yolo_txt_file(self, yolo_lst, save_bg_file_name, YOLO_txt = False):\n",
    "        save = save_bg_file_name + '.txt'\n",
    "        if YOLO_txt:\n",
    "            with open(save, \"w\") as txt_object:\n",
    "                for yolo_info in yolo_lst:\n",
    "                    for i in range(len(yolo_info)):\n",
    "                        txt_object.write(str(yolo_info[i]))\n",
    "                        if i < len(yolo_info)-1:\n",
    "                            txt_object.write(' ')\n",
    "                    \n",
    "                    txt_object.write('\\n')\n",
    "\n",
    "\n",
    "    # returns a list of sampled paths\n",
    "    def sample_objects(self, sub_obj_folder_path, num_of_objects):\n",
    "        # load object list\n",
    "        lst = os.listdir(sub_obj_folder_path)\n",
    "        jpg_filter = filter(lambda x:x[-4:]== '.jpg' or x[-4:] == '.png', lst)\n",
    "        lst = list(jpg_filter)\n",
    "        \n",
    "        if num_of_objects>len(lst):\n",
    "            num_of_objects = random.randint(1,len(lst))\n",
    "        else:\n",
    "            num_of_objects = num_of_objects\n",
    "\n",
    "        # randomly sample object paths\n",
    "        sampled_object_paths = random.sample(lst, num_of_objects)\n",
    "\n",
    "        # get list of full-path objects\n",
    "        for indx in range(len(sampled_object_paths)):\n",
    "            path = sampled_object_paths[indx]\n",
    "            fullpath = sub_obj_folder_path + '\\\\' + path\n",
    "            sampled_object_paths[indx] = fullpath\n",
    "\n",
    "        return sampled_object_paths\n",
    "\n",
    "\n",
    "\n",
    "    # get list of sampled object paths \n",
    "    def get_object_paths(self, main_object_folder_path, num_of_objects, same_environment = None):\n",
    "        lst_object_paths = []\n",
    "        lst_names = []\n",
    "\n",
    "        # if path is list: list of different object folder paths\n",
    "        if type(main_object_folder_path) is list:\n",
    "\n",
    "            # iterate through each object folder path\n",
    "            for obj_folder in main_object_folder_path:\n",
    "    \n",
    "                foldername = obj_folder.split('\\\\')[-1]\n",
    "                \n",
    "                #only consider objects from same cam view: e.g object: cam1\\obj_name , bg: cam1\\bg_name\n",
    "                if same_environment and foldername in same_environment:\n",
    "                    sampled_object_paths = self.sample_objects(obj_folder, num_of_objects)\n",
    "                    lst_names.append(foldername)\n",
    "                    return (sampled_object_paths, lst_names)\n",
    "                \n",
    "                # sample each sub folder\n",
    "                sampled_object_paths = self.sample_objects(obj_folder, num_of_objects)\n",
    "\n",
    "                lst_object_paths.extend(sampled_object_paths)\n",
    "                lst_names.append(foldername)\n",
    "\n",
    "            # sample all object paths: to get a variety of different objects\n",
    "            main_sampled_object_paths = random.sample(lst_object_paths, num_of_objects)\n",
    "\n",
    "            # sort object name types in alpha-numeric order\n",
    "            lst_names.sort()\n",
    "            return (main_sampled_object_paths, lst_names)\n",
    "\n",
    "        # if path is string: 1 object folder path\n",
    "        elif type(main_object_folder_path) is str:\n",
    "            foldername = main_object_folder_path.split('\\\\')[-1]\n",
    "            \n",
    "            #only consider persons from same cam view\n",
    "            if same_environment and foldername in same_environment:\n",
    "                sampled_object_paths = self.sample_objects(main_object_folder_path, num_of_objects)\n",
    "                lst_names.append(foldername)\n",
    "                return (sampled_object_paths, lst_names)\n",
    "            \n",
    "            # sample object folder\n",
    "            sampled_object_paths = self.sample_objects(main_object_folder_path, num_of_objects)\n",
    "\n",
    "            lst_object_paths.extend(sampled_object_paths)\n",
    "            lst_names.append(foldername)\n",
    "            return (lst_object_paths, lst_names)\n",
    "        else:\n",
    "            print('invalid object path!')\n",
    "\n",
    "\n",
    "\n",
    "    ########################\n",
    "    # Executable Functions #\n",
    "    ########################\n",
    "\n",
    "    # returns augmented background image with specified number of objects \n",
    "    def augmented_bg_with_objects(self, bg_path, num_of_objects, object_folder_path, same_environment=False):\n",
    "        \n",
    "        # create YOLO list for YOLO text file\n",
    "        YOLO_lst = []\n",
    "\n",
    "        # get filename of background\n",
    "        bg_name = bg_path.split('\\\\')[-1]\n",
    "        if 'cam' in bg_name:\n",
    "            TAV_cam_view = bg_name\n",
    "        else:\n",
    "            TAV_cam_view = None\n",
    "\n",
    "        # get list of object image paths\n",
    "        sampled_object_paths, YOLO_CLASSES = self.get_object_paths(object_folder_path, num_of_objects, same_environment=TAV_cam_view)\n",
    "        \n",
    "        # background image dimension\n",
    "        bg_img = Image.open(bg_path).convert('RGB')\n",
    "        frame_width, frame_height = bg_img.size\n",
    "\n",
    "        # create non-overlapping coordinates list\n",
    "        non_overlap_size_lst = []\n",
    "\n",
    "        for obj_path in sampled_object_paths:\n",
    "            # object class name\n",
    "            class_name = obj_path.split('\\\\')[-2]\n",
    "\n",
    "            # initialize smallest and largest object sizes and boundary coordinates\n",
    "            nearest_obj, furthest_obj, boundary_x, boundary_y = self.initialize_sizes_and_coordinates(bg_path, scale=1, TAV_cam_view = TAV_cam_view, same_environment=same_environment)\n",
    "\n",
    "            # get random coordinates and desired size given those coordinates and updated coordinates list\n",
    "            random_coordinates, desired_obj_size, non_overlap_size_lst = self.get_random_coords_and_size(obj_path, non_overlap_size_lst, frame_width, frame_height, nearest_obj, furthest_obj, boundary_x, boundary_y, TAV_cam_view, same_environment=same_environment)\n",
    "\n",
    "            # resize object image based on desired size\n",
    "            object_img = Image.open(obj_path)\n",
    "\n",
    "            if not same_environment:\n",
    "                resized_object_img = self.image_resize(object_img, desired_obj_size, TAV_cam_view)\n",
    "            else:\n",
    "                #NOTE: seems like strollers were shrunk by half its original size, so resizing is needed here\n",
    "                resized_object_img = object_img.resize((object_img.size[0]*2,object_img.size[1]*2))\n",
    "\n",
    "            # randomly augment resized object\n",
    "            resized_object_img = self.random_augmentv1(resized_object_img)\n",
    "\n",
    "            # obtain image with mask\n",
    "            img_mask, yolo_info = self.img_with_mask(resized_object_img, bg_img, random_coordinates, frame_width, frame_height, TAV_cam_view)\n",
    "            \n",
    "            # overlay object on background\n",
    "            bg_img = self.overlay_img_on_bg(img_mask, bg_img, random_coordinates)\n",
    "\n",
    "            # insert CLASSID into yolo_info list\n",
    "            yolo_info.insert(0, YOLO_CLASSES.index(class_name))\n",
    "            YOLO_lst.append(yolo_info)\n",
    "        YOLO_lst = []\n",
    "        #convert to RGB format\n",
    "        # try:\n",
    "        #     bg_img = format_rgb(bg_img)\n",
    "        # except:\n",
    "        #     pass\n",
    "        \n",
    "        return bg_img, YOLO_lst\n",
    "\n",
    "\n",
    "    # generate fallen person on background\n",
    "    def augmented_bg_with_fallen_person(self, bg_path, num_of_objects, obj_folder_path):\n",
    "        # create YOLO list for YOLO text file\n",
    "        YOLO_lst = []\n",
    "\n",
    "        # get filename of background\n",
    "        bg_name = bg_path.split('\\\\')[-1]\n",
    "        if 'cam' in bg_name:\n",
    "            TAV_cam_view = bg_name\n",
    "        else:\n",
    "            TAV_cam_view = None\n",
    "        \n",
    "        # get list of object image paths\n",
    "        sampled_object_paths, YOLO_CLASSES = self.get_object_paths(obj_folder_path, num_of_objects, same_environment=TAV_cam_view)\n",
    "\n",
    "        # background image dimension\n",
    "        bg_img = Image.open(bg_path).convert('RGB')\n",
    "        frame_width, frame_height = bg_img.size\n",
    "\n",
    "        # create non-overlapping coordinates list\n",
    "        non_overlap_size_lst = []\n",
    "\n",
    "        for obj_path in sampled_object_paths:\n",
    "            # object class folder name\n",
    "            class_name = obj_path.split('\\\\')[-2]\n",
    "            \n",
    "            # initialize smallest and largest object sizes and boundary coordinates\n",
    "            nearest_obj, furthest_obj, boundary_x, boundary_y = self.initialize_sizes_and_coordinates(bg_path, scale=1, TAV_cam_view=TAV_cam_view, same_environment=True)\n",
    "\n",
    "            # get random coordinates and desired size given those coordinates and updated coordinates list\n",
    "            random_coordinates, desired_obj_size, non_overlap_size_lst = self.get_random_coords_and_size(obj_path, non_overlap_size_lst, frame_width, frame_height, nearest_obj, furthest_obj, boundary_x, boundary_y, TAV_cam_view, same_environment = True)\n",
    "\n",
    "            # resize object image based on desired size\n",
    "            object_img = Image.open(obj_path)\n",
    "            # resized_object_img = self.image_resize(object_img, desired_obj_size, TAV_cam_view)\n",
    "\n",
    "            # augment resized object\n",
    "            resized_object_img, head_yolo_info = self.random_augmentv2(object_img, bg_img, random_coordinates, head_bbox_file=obj_path, fallen_person=True)\n",
    "\n",
    "            # obtain image with mask\n",
    "            img_mask, person_yolo_info = self.img_with_mask(resized_object_img, bg_img, random_coordinates, frame_width, frame_height, TAV_cam_view)\n",
    "            \n",
    "            # overlay object on background\n",
    "            bg_img = self.overlay_img_on_bg(img_mask, bg_img, random_coordinates)\n",
    "\n",
    "            # insert CLASSID into yolo_info list\n",
    "            person_yolo_info.insert(0, 1) #insert index '1' since 'person' is index '1' in YOLOv4PA\n",
    "            \n",
    "            # append information to YOLO list if information is valid\n",
    "            if self.verify_yolo_information(person_yolo_info):\n",
    "                YOLO_lst.append(person_yolo_info)\n",
    "\n",
    "            if self.verify_yolo_information(head_yolo_info):    \n",
    "                YOLO_lst.append(head_yolo_info)\n",
    "                \n",
    "        #convert to RGB format\n",
    "        # try:\n",
    "        #     bg_img = format_rgb(bg_img)\n",
    "        # except:\n",
    "        #     pass\n",
    "        \n",
    "        return bg_img, YOLO_lst\n",
    "    \n",
    "\n",
    "    # generate augmented backgrounds with objects\n",
    "    def generate_augmented_backgrounds(self, num_of_augmented_frames, num_of_objects, obj_folder_path, bg_images_path, save_path, YOLO_txt = False, fallen_person = None):\n",
    "        # num_of_augmented_frames: specify number of frames to be augmented\n",
    "        # num_of_objects: specified number of objects if <10, else, randomly generate number of objects to put inside each bg image\n",
    "        # obj_folder_path: path for folder of objects\n",
    "        # bg_images_path: path for folder of backgrounds\n",
    "        # save_path: path to save augmented images\n",
    "        # YOLO_txt: True if generating yolo text files, else False\n",
    "        \n",
    "    \n",
    "\n",
    "        \n",
    "        for i in tqdm(range(num_of_augmented_frames)):\n",
    "            # get list of background image paths\n",
    "            lst_bg_paths = os.listdir(bg_images_path)\n",
    "\n",
    "            # randomly sample background image in the list\n",
    "            bg_name = random.choice(lst_bg_paths)\n",
    "            bg_path = bg_images_path + '\\\\' + bg_name\n",
    "            bg_name = bg_name.split('.')[0]\n",
    "\n",
    "            # complete path to save background image\n",
    "            save_bg_name = save_path + '\\\\' + f'{bg_name}_{i}'\n",
    "\n",
    "            #NOTE: there are occasions where random coordinates generated contain a 0, thus we avoid an error by implementing Try/Except\n",
    "            try: \n",
    "                # get augmented background and YOLO list\n",
    "                if fallen_person:\n",
    "                    bg_img,YOLO_lst = self.augmented_bg_with_fallen_person(bg_path, num_of_objects, obj_folder_path)\n",
    "\n",
    "                else:\n",
    "                    bg_img, YOLO_lst = self.augmented_bg_with_objects(bg_path, num_of_objects, obj_folder_path, same_environment=False)\n",
    "\n",
    "                # save augmented background (and YOLO txt file if activated)\n",
    "                bg_img.save(save_bg_name + '.jpg')\n",
    "                self.create_yolo_txt_file(YOLO_lst, save_bg_name, YOLO_txt)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [11:46<00:00, 21.22it/s]\n"
     ]
    }
   ],
   "source": [
    "########################################################################################\n",
    "# TESTING\n",
    "bg_path = r\"D:\\Daniel\\PMD\\YOLOv4\\falling_person\\TAV_backgrounds\\night_TAV_backgrounds\\cam1_night.jpg\"\n",
    "obj_folder_path = r\"D:\\Daniel\\PMD\\YOLOv4\\falling_person\\labelled_pedestrians\\night\\cam1\"\n",
    "obj_folder_path = r\"D:\\Daniel\\PMD\\YOLOv4\\YOLOv4_negatives\\PMDs\\pmd_pngs\\bicycle_all\"\n",
    "# img, lst = ObjectAugmentation().augmented_bg_with_fallen_person(bg_path, 1, obj_folder_path)\n",
    "# img, lst = ObjectAugmentation().augmented_bg_with_objects(bg_path, 2, obj_folder_path)\n",
    "# plt.imshow(img)\n",
    "#########################################################################################\n",
    "\n",
    "bg_images_paths = [ #dogs\n",
    "                    r\"D:\\Daniel\\PMD\\YOLOv4\\falling_person\\TAV_backgrounds\\night_TAV_backgrounds\",\n",
    "\n",
    "                    #person\n",
    "                    r\"D:\\Daniel\\PMD\\YOLOv4\\falling_person\\TAV_backgrounds\\night_TAV_backgrounds\",\n",
    "\n",
    "                    #cones\n",
    "                    r'D:\\Daniel\\PMD\\YOLOv4\\YOLOv4_negatives\\cones\\background_images',\n",
    "\n",
    "                    #colour noise\n",
    "                    r'D:\\Daniel\\PMD\\YOLOv4\\YOLOv4_negatives\\cones\\background_images',\n",
    "\n",
    "                    #PMDs\n",
    "                    r\"D:\\Daniel\\PMD\\YOLOv4\\falling_person\\TAV_backgrounds\\day_night_TAV_backgrounds\"\n",
    "                    ]\n",
    "\n",
    "obj_paths = [   #dogs\n",
    "                [r'D:\\Daniel\\PMD\\YOLOv4\\YOLOv4_negatives\\dogs\\TAV_dog_images\\cam1',\n",
    "                r'D:\\Daniel\\PMD\\YOLOv4\\YOLOv4_negatives\\dogs\\TAV_dog_images\\cam2',\n",
    "                r'D:\\Daniel\\PMD\\YOLOv4\\YOLOv4_negatives\\dogs\\TAV_dog_images\\cam3',\n",
    "                r'D:\\Daniel\\PMD\\YOLOv4\\YOLOv4_negatives\\dogs\\TAV_dog_images\\cam4'],\n",
    "                \n",
    "                #person\n",
    "                [r\"D:\\Daniel\\PMD\\YOLOv4\\falling_person\\labelled_pedestrians\\night\\cam1\",\n",
    "                r\"D:\\Daniel\\PMD\\YOLOv4\\falling_person\\labelled_pedestrians\\night\\cam2\",\n",
    "                r\"D:\\Daniel\\PMD\\YOLOv4\\falling_person\\labelled_pedestrians\\night\\cam3\",\n",
    "                r\"D:\\Daniel\\PMD\\YOLOv4\\falling_person\\labelled_pedestrians\\night\\cam4\"],\n",
    "\n",
    "                #cones\n",
    "                r'D:\\Daniel\\PMD\\YOLOv4\\YOLOv4_negatives\\cones\\cone_png',\n",
    "\n",
    "                #colour noise\n",
    "                r\"D:\\Daniel\\PMD\\YOLOv4\\YOLOv4_negatives\\colour_noise\\colour_noise_pngs\",\n",
    "            \n",
    "                #PMDs\n",
    "                [r\"D:\\Daniel\\PMD\\YOLOv4\\YOLOv4_negatives\\PMDs\\pmd_pngs\\bicycle_all\",\n",
    "                r\"D:\\Daniel\\PMD\\YOLOv4\\YOLOv4_negatives\\PMDs\\pmd_pngs\\motorcycle_all\",\n",
    "                r\"D:\\Daniel\\PMD\\YOLOv4\\YOLOv4_negatives\\PMDs\\pmd_pngs\\scooter_all\"]\n",
    "            ]\n",
    "\n",
    "save_paths = [      #dogs\n",
    "                    r\"D:\\Daniel\\PMD\\YOLOv4\\YOLOv4_negatives\\dogs\\augmented_bg_frames\\dogs_augmented_bg_frames_3\",\n",
    "\n",
    "                    #person\n",
    "                    r\"D:\\Daniel\\PMD\\YOLOv4\\falling_person\\augmented_bg_frames\\person_augmented_backgrounds_3\",\n",
    "                    \n",
    "                    #cones\n",
    "                    r\"D:\\Daniel\\PMD\\YOLOv4\\YOLOv4_negatives\\cones\\augmented_bg_frames\\cones_augmented_bg_frames_2\",\n",
    "\n",
    "                    #colour noise\n",
    "                    r\"D:\\Daniel\\PMD\\YOLOv4\\YOLOv4_negatives\\colour_noise\\augmented_bg_frames\\noise_augmented_frames_2\",\n",
    "            \n",
    "                    #PMDs\n",
    "                    r\"D:\\Daniel\\PMD\\YOLOv4\\YOLOv4_negatives\\PMDs\\pmd_augmented_bg_frames\"\n",
    "            ]\n",
    "\n",
    "\n",
    "\n",
    "indx = 1\n",
    "bg_images_path = bg_images_paths[indx]\n",
    "obj_folder_path = obj_paths[indx]\n",
    "save_path = save_paths[indx]\n",
    "\n",
    "# Non-living objects\n",
    "# ObjectAugmentation().generate_augmented_backgrounds(7000, 3, obj_folder_path, bg_images_path, save_path, YOLO_txt=True, fallen_person=False)\n",
    "\n",
    "\n",
    "# Living objects\n",
    "ObjectAugmentation().generate_augmented_backgrounds(15000, 1, obj_folder_path, bg_images_path, save_path, YOLO_txt=True, fallen_person=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_folder_path = r\"D:\\Daniel\\PMD\\YOLOv4\\YOLOv4_negatives\\colour_noise\\colour_noise_imgs\"\n",
    "save_path = r\"D:\\Daniel\\PMD\\YOLOv4\\falling_person\\labelled_pedestrians\\night\"\n",
    "pathnames = [r\"D:\\Daniel\\PMD\\YOLOv4\\falling_person\\labelled_pedestrians\\night\\cam1\\Screenshot 2021-11-23 at 12.15.45 PM.jpg\",\n",
    "r\"D:\\Daniel\\PMD\\YOLOv4\\falling_person\\labelled_pedestrians\\night\\cam1\\Screenshot 2021-11-23 at 12.16.28 PM.jpg\"]\n",
    "for path in pathnames:\n",
    "    pathname = path.split('\\\\')[-1].split('.jpg')[0]\n",
    "    # img = cv2.imread(path)\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_BGRA2RGB)\n",
    "    img = ObjectAugmentation().png_format(path, 220)\n",
    "    cv2.imwrite(save_path + '\\\\' + pathname + '.png', img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([300. , 337.5])"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([120 , 135])*2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8b782a351391c2b504ef617b3579652ee72b916bcd226c7dd794f4652190563"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('tensorflow2': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
